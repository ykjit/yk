//! The X64 backend.
//!
//! ## Terminology
//!
//! We split registers into two main categories: *general purpose* registers are the 16 registers
//! from `rax` to `r15`; and *floating point* registers are the `xmm` registers.
//!
//!
//! ## Pointers
//!
//! We assume that pointers are always 64 bits and can fit into any general purpose register.
//!
//! From the perspective of the register allocator, we can treat 64 bits pointers in general
//! purpose registers as either [RegFill::Undefined] or [RegFill::Zeroed]. In general, the most
//! efficient thing we can do for pointers is accept [RegFill::Undefined] for pointer inputs and
//! output [RegFill::Zeroed] for pointer outputs. The former means pointers entering the trace from
//! LLVM or external calls do not need to be zero extended. The latter means that pointers
//! generated by instructions such as `dynptradd` do not cause code to be generated if later used
//! in instructions such as `ptrtoint`.
//!
//!
//! ## Floating point
//!
//! We assume that floating point fills are irrelevant -- because we always use only the part of of
//! an `xmm` register that contains data we want -- and always use `RegFill::Undefined`.
//!
//!
//! ## Generating efficient code
//!
//! x64 frequently has several ways that equivalent behaviour can be encoded. This module tries
//! fairly hard to generate the most efficient possible code: this sometimes requires jumping
//! through a number of hoops!

#[cfg(not(test))]
use crate::aotsmp::AOT_STACKMAPS;
use crate::{
    compile::{
        CompilationError,
        j2::{
            compiled_trace::{DeoptFrame, J2CompiledGuard, J2CompiledTrace, J2CompiledTraceKind},
            hir::*,
            hir_to_asm::HirToAsmBackend,
            regalloc::{AnyOfFill, RegAlloc, RegCnstr, RegCnstrFill, RegFill, VarLoc, VarLocs},
            x64::{
                asm::{Asm, BLOCK_ALIGNMENT, LabelIdx, RelocKind},
                x64regalloc::{ALL_XMM_REGS, NORMAL_GP_REGS, Reg},
            },
        },
        jitc_yk::aot_ir,
    },
    mt::TraceId,
};
use array_concat::concat_arrays;
use iced_x86::{Code, Instruction as IcedInst, MemoryOperand, Register as IcedReg};
use index_vec::IndexVec;
use smallvec::{SmallVec, smallvec};
use std::{
    assert_matches::{assert_matches, debug_assert_matches},
    collections::HashMap,
    ffi::c_void,
    sync::Arc,
};

#[derive(Debug)]
pub(in crate::compile::j2) struct X64HirToAsm<'a> {
    m: &'a Mod<Reg>,
    asm: Asm,
    /// The data section: we map any given (align, byte sequence) pair to [LabelIdx]s, which will
    /// eventually be output as their own pseudo-block.
    data_sec: HashMap<Vec<u8>, (u32, LabelIdx)>,
    guards: IndexVec<GuardRestoreIdx, IntermediateGuard>,
}

impl<'a> X64HirToAsm<'a> {
    pub(in crate::compile::j2) fn new(m: &'a Mod<Reg>) -> Self {
        Self {
            m,
            asm: Asm::new(m),
            data_sec: HashMap::new(),
            guards: IndexVec::new(),
        }
    }

    /// Return a [LabelIdx] for `data`, ensuring that it is aligned to at least `align` bytes.
    /// Note: this function can cache `data` i.e. calling it twice with equivalent `data` can lead
    /// to the same [LabelIdx] being returned.
    ///
    /// # Panics
    ///
    /// If `align` is not a power of 2.
    fn push_data(&mut self, align: u32, data: &[u8]) -> LabelIdx {
        assert!(align.is_power_of_two());
        if let Some((cur_align, lidx)) = self.data_sec.get(data) {
            let lidx = *lidx;
            if align > *cur_align {
                // Higher alignment requirements take precedence.
                self.data_sec.get_mut(data).unwrap().0 = align;
            }
            return lidx;
        }

        assert!(!data.is_empty() && data.len() <= 16);
        let lidx = self.asm.mk_label();
        self.data_sec.insert(data.to_owned(), (align, lidx));
        lidx
    }

    /// If `iidx` represents a zero-extended const which can safely be represented as an `imm8`
    /// return `Some`.
    fn zero_ext_op_for_imm8(&self, b: &Block, iidx: InstIdx) -> Option<u32> {
        if let Inst::Const(Const { kind, .. }) = b.inst(iidx) {
            match kind {
                ConstKind::Double(_) => unreachable!(),
                ConstKind::Float(_) => unreachable!(),
                ConstKind::Int(x) => x.to_zero_ext_u8().map(u32::from),
                ConstKind::Ptr(_) => todo!(),
            }
        } else {
            None
        }
    }

    /// If `iidx` represents a sign-extended const which can safely be represented as an `imm32`
    /// return `Some`. The value returned is suitable for both 32-bit and 64-bit instructions,
    /// where the latter implicitly sign extends 32-bit values to 64-bits.
    fn sign_ext_op_for_imm32(&self, b: &Block, iidx: InstIdx) -> Option<i32> {
        if let Inst::Const(Const { kind, .. }) = b.inst(iidx) {
            match kind {
                ConstKind::Double(_) => unreachable!(),
                ConstKind::Float(_) => unreachable!(),
                ConstKind::Int(x) => x.to_sign_ext_i32(),
                ConstKind::Ptr(x) => i32::try_from(*x).ok(),
            }
        } else {
            None
        }
    }

    /// If `iidx` represents a zero-extended const which can safely be represented as an `imm32`
    /// return `Some`. The value returned is suitable for both 32-bit and 64-bit instructions,
    /// where the latter implicitly sign extends 32-bit values to 64-bits.
    fn zero_ext_op_for_imm32(&self, b: &Block, bitw: u32, iidx: InstIdx) -> Option<i32> {
        if let Inst::Const(Const { kind, .. }) = b.inst(iidx) {
            match kind {
                ConstKind::Double(_) => unreachable!(),
                ConstKind::Float(_) => unreachable!(),
                ConstKind::Int(x) => match bitw {
                    1..=32 => x.to_zero_ext_u32().map(|x| x.cast_signed()),
                    64 => {
                        if let Some(x) = x.to_sign_ext_i32()
                            && let Ok(x) = u32::try_from(x)
                        {
                            Some(x.cast_signed())
                        } else {
                            None
                        }
                    }
                    x => todo!("{x}"),
                },
                ConstKind::Ptr(x) => match bitw {
                    64 => {
                        if let Ok(x) = i32::try_from(*x)
                            && let Ok(x) = u32::try_from(x)
                        {
                            Some(x.cast_signed())
                        } else {
                            None
                        }
                    }
                    _ => unreachable!(),
                },
            }
        } else {
            None
        }
    }

    /// If, while processing `cur_iidx`, the operand at `op_iidx` is:
    ///
    ///   1. A `Load` instruction (possibly indirectly reachable by `PtrAdd`s),
    ///   2. and that `Load` cannot be effected by other operations,
    ///
    /// then return the [InstIdx] of the `Load` plus its (x64-friendly) displacement.
    fn try_load_to_mem_op(
        &self,
        b: &Block,
        cur_iidx: InstIdx,
        op_iidx: InstIdx,
    ) -> Option<(InstIdx, i64)> {
        if let Inst::Load(Load {
            ptr,
            is_volatile: false,
            ..
        }) = b.inst(op_iidx)
        {
            assert!(op_iidx < cur_iidx);
            if !b.heap_effects_on(op_iidx, op_iidx + 1..cur_iidx) {
                return self.flatten_ptradd_chain(b, *ptr);
            }
        }
        None
    }

    /// If `ptr` is a [PtrAdd], follow the possible chain of [PtrAdd] instructions it refers to,
    /// giving a "base" pointer and offset.
    ///
    /// For example given this trace:
    ///
    /// ```text
    /// %0: ptr = arg
    /// %1: ptradd %0, 1
    /// %2: i8 = load %1
    /// %3: ptradd %0, 1
    /// %4: i8 = load %1
    /// ```
    ///
    /// for the pointer at instruction 2, this will return `(%1, 1)` and for the pointer at
    /// instruction 4 it will return `(%1, 2)`.
    fn flatten_ptradd_chain(&self, b: &Block, mut ptr: InstIdx) -> Option<(InstIdx, i64)> {
        let mut off = 0;
        while let Inst::PtrAdd(PtrAdd {
            ptr: cnd_ptr,
            off: cnd_off,
            ..
        }) = b.inst(ptr)
        {
            off += *cnd_off;
            ptr = *cnd_ptr;
        }
        Some((ptr, i64::from(off)))
    }

    /// Generate code for a guard whose `cond` directly refers to an [ICmp].
    ///
    /// # Panics
    ///
    /// If `cond` is not an [ICmp].
    fn i_icmp_guard(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Guard {
            expect,
            gridx,
            cond,
            entry_vars,
            ..
        }: &Guard,
    ) -> Result<LabelIdx, CompilationError> {
        let Inst::ICmp(ICmp {
            pred,
            lhs,
            rhs,
            samesign: _,
        }) = b.inst(*cond)
        else {
            panic!()
        };

        let bitw = b.inst_bitw(self.m, *lhs);
        let (imm, mut in_fill) = if pred == &IPred::Eq {
            (self.sign_ext_op_for_imm32(b, *rhs), RegCnstrFill::Zeroed)
        } else if pred.is_signed() {
            (self.sign_ext_op_for_imm32(b, *rhs), RegCnstrFill::Signed)
        } else {
            (
                self.zero_ext_op_for_imm32(b, bitw, *rhs),
                RegCnstrFill::Zeroed,
            )
        };
        if bitw == 32 || bitw == 64 {
            // We can relax sign / zero fill for values that are exactly 32/64 bit.
            in_fill = RegCnstrFill::Undefined;
        }
        let c = if *expect {
            match pred {
                IPred::Eq => Code::Jne_rel32_64,
                IPred::Ne => Code::Je_rel32_64,
                IPred::Ugt => Code::Jbe_rel32_64,
                IPred::Uge => Code::Jb_rel32_64,
                IPred::Ult => Code::Jae_rel32_64,
                IPred::Ule => Code::Ja_rel32_64,
                IPred::Sgt => Code::Jle_rel32_64,
                IPred::Sge => Code::Jl_rel32_64,
                IPred::Slt => Code::Jge_rel32_64,
                IPred::Sle => Code::Jg_rel32_64,
            }
        } else {
            match pred {
                IPred::Eq => Code::Je_rel32_64,
                IPred::Ne => Code::Jne_rel32_64,
                IPred::Ugt => Code::Ja_rel32_64,
                IPred::Uge => Code::Jae_rel32_64,
                IPred::Ult => Code::Jb_rel32_64,
                IPred::Ule => Code::Jbe_rel32_64,
                IPred::Sgt => Code::Jg_rel32_64,
                IPred::Sge => Code::Jge_rel32_64,
                IPred::Slt => Code::Jl_rel32_64,
                IPred::Sle => Code::Jle_rel32_64,
            }
        };
        if let Some(imm) = imm {
            let rmop = if let Some((load_iidx, off)) = self.try_load_to_mem_op(b, iidx, *lhs) {
                let [lhsr, _] = ra.alloc(
                    self,
                    iidx,
                    [
                        RegCnstr::Input {
                            in_iidx: load_iidx,
                            in_fill,
                            regs: &NORMAL_GP_REGS,
                            clobber: false,
                        },
                        RegCnstr::KeepAlive {
                            gridx: *gridx,
                            iidxs: entry_vars,
                        },
                    ],
                )?;
                RegOrMemOp::MemOp(lhsr, off)
            } else {
                let [lhsr, _] = ra.alloc(
                    self,
                    iidx,
                    [
                        RegCnstr::Input {
                            in_iidx: *lhs,
                            in_fill,
                            regs: &NORMAL_GP_REGS,
                            clobber: false,
                        },
                        RegCnstr::KeepAlive {
                            gridx: *gridx,
                            iidxs: entry_vars,
                        },
                    ],
                )?;
                RegOrMemOp::Reg(lhsr)
            };

            let label = self.asm.mk_label();
            self.asm.push_reloc(
                IcedInst::with_branch(c, 0),
                RelocKind::RipRelativeWithLabel(label),
            );
            self.i_icmp_const(bitw, rmop, imm);
            Ok(label)
        } else {
            let (rmop, rhsr) =
                if let Some((load_iidx, off)) = self.try_load_to_mem_op(b, iidx, *lhs) {
                    let [lhsr, rhsr, _] = ra.alloc(
                        self,
                        iidx,
                        [
                            RegCnstr::Input {
                                in_iidx: load_iidx,
                                in_fill: in_fill.clone(),
                                regs: &NORMAL_GP_REGS,
                                clobber: false,
                            },
                            RegCnstr::Input {
                                in_iidx: *rhs,
                                in_fill,
                                regs: &NORMAL_GP_REGS,
                                clobber: false,
                            },
                            RegCnstr::KeepAlive {
                                gridx: *gridx,
                                iidxs: entry_vars,
                            },
                        ],
                    )?;
                    (RegOrMemOp::MemOp(lhsr, off), rhsr)
                } else {
                    let [lhsr, rhsr, _] = ra.alloc(
                        self,
                        iidx,
                        [
                            RegCnstr::Input {
                                in_iidx: *lhs,
                                in_fill: in_fill.clone(),
                                regs: &NORMAL_GP_REGS,
                                clobber: false,
                            },
                            RegCnstr::Input {
                                in_iidx: *rhs,
                                in_fill,
                                regs: &NORMAL_GP_REGS,
                                clobber: false,
                            },
                            RegCnstr::KeepAlive {
                                gridx: *gridx,
                                iidxs: entry_vars,
                            },
                        ],
                    )?;
                    (RegOrMemOp::Reg(lhsr), rhsr)
                };
            let label = self.asm.mk_label();
            self.asm.push_reloc(
                IcedInst::with_branch(c, 0),
                RelocKind::RipRelativeWithLabel(label),
            );
            self.i_icmp_reg(bitw, rmop, rhsr);
            Ok(label)
        }
    }

    fn i_icmp_const(&mut self, bitw: u32, rmop: RegOrMemOp, rhs: i32) {
        if rhs == 0
            && let RegOrMemOp::Reg(reg) = rmop
        {
            self.asm.push_inst(match bitw {
                1..=32 => IcedInst::with2(Code::Test_rm32_r32, reg.to_reg32(), reg.to_reg32()),
                64 => IcedInst::with2(Code::Test_rm64_r64, reg.to_reg64(), reg.to_reg64()),
                x => todo!("{x}"),
            });
        } else {
            self.asm.push_inst(match bitw {
                8 => match rmop {
                    RegOrMemOp::Reg(reg) => {
                        IcedInst::with2(Code::Cmp_rm32_imm32, reg.to_reg32(), rhs)
                    }
                    RegOrMemOp::MemOp(reg, disp) => IcedInst::with2(
                        Code::Cmp_rm8_imm8,
                        MemoryOperand::with_base_displ(reg.to_reg64(), disp),
                        rhs,
                    ),
                },
                16 => match rmop {
                    RegOrMemOp::Reg(reg) => {
                        IcedInst::with2(Code::Cmp_rm32_imm32, reg.to_reg32(), rhs)
                    }
                    RegOrMemOp::MemOp(reg, disp) => IcedInst::with2(
                        Code::Cmp_rm16_imm16,
                        MemoryOperand::with_base_displ(reg.to_reg64(), disp),
                        rhs,
                    ),
                },
                32 => match rmop {
                    RegOrMemOp::Reg(reg) => {
                        IcedInst::with2(Code::Cmp_rm32_imm32, reg.to_reg32(), rhs)
                    }
                    RegOrMemOp::MemOp(reg, disp) => IcedInst::with2(
                        Code::Cmp_rm32_imm32,
                        MemoryOperand::with_base_displ(reg.to_reg64(), disp),
                        rhs,
                    ),
                },
                64 => match rmop {
                    RegOrMemOp::Reg(reg) => {
                        IcedInst::with2(Code::Cmp_rm64_imm32, reg.to_reg64(), rhs)
                    }
                    RegOrMemOp::MemOp(reg, disp) => IcedInst::with2(
                        Code::Cmp_rm64_imm32,
                        MemoryOperand::with_base_displ(reg.to_reg64(), disp),
                        rhs,
                    ),
                },
                x => todo!("{x}"),
            });
        }
    }

    fn i_icmp_reg(&mut self, bitw: u32, rmop: RegOrMemOp, rhsr: Reg) {
        self.asm.push_inst(match rmop {
            RegOrMemOp::Reg(lhsr) => match bitw {
                1..=32 => IcedInst::with2(Code::Cmp_rm32_r32, lhsr.to_reg32(), rhsr.to_reg32()),
                64 => IcedInst::with2(Code::Cmp_rm64_r64, lhsr.to_reg64(), rhsr.to_reg64()),
                x => todo!("{x}"),
            },
            RegOrMemOp::MemOp(lhsr, disp) => match bitw {
                32 => IcedInst::with2(
                    Code::Cmp_rm32_r32,
                    MemoryOperand::with_base_displ(lhsr.to_reg32(), disp),
                    rhsr.to_reg32(),
                ),
                64 => IcedInst::with2(
                    Code::Cmp_rm64_r64,
                    MemoryOperand::with_base_displ(lhsr.to_reg64(), disp),
                    rhsr.to_reg64(),
                ),
                x => todo!("{x}"),
            },
        });
    }

    fn _i_load_float(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Load {
            tyidx,
            ptr,
            is_volatile: _,
        }: &Load,
    ) -> Result<(), CompilationError> {
        assert_matches!(self.m.ty(*tyidx), Ty::Double | Ty::Float);

        let (ptr, off) = self.flatten_ptradd_chain(b, *ptr).unwrap_or((*ptr, 0));
        let [ptrr, outr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: ptr,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::Output {
                    out_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    can_be_same_as_input: false,
                },
            ],
        )?;
        let memop = if off == 0 {
            MemoryOperand::with_base(ptrr.to_reg64())
        } else {
            MemoryOperand::with_base_displ(ptrr.to_reg64(), off)
        };
        self.asm.push_inst(match self.m.ty(*tyidx) {
            Ty::Double => IcedInst::with2(Code::Movsd_xmm_xmmm64, outr.to_xmm(), memop),
            Ty::Float => IcedInst::with2(Code::Movss_xmm_xmmm32, outr.to_xmm(), memop),
            _ => unreachable!(),
        });

        Ok(())
    }

    fn _i_load_intptr(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Load {
            tyidx,
            ptr,
            is_volatile: _,
        }: &Load,
    ) -> Result<(), CompilationError> {
        assert_matches!(self.m.ty(*tyidx), Ty::Int(_) | Ty::Ptr(0));
        let (ptr, off) = self.flatten_ptradd_chain(b, *ptr).unwrap_or((*ptr, 0));
        let [(ptrr, _), (outr, out_fill)] = ra.alloc_with_fills(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: ptr,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::Output {
                    out_fill: RegCnstrFill::AnyOf(
                        AnyOfFill::new()
                            .with_undefined()
                            .with_signed()
                            .with_zeroed(),
                    ),
                    regs: &NORMAL_GP_REGS,
                    can_be_same_as_input: true,
                },
            ],
        )?;
        let memop = if off == 0 {
            MemoryOperand::with_base(ptrr.to_reg64())
        } else {
            MemoryOperand::with_base_displ(ptrr.to_reg64(), off)
        };

        self.asm.push_inst(match self.m.ty(*tyidx) {
            Ty::Int(bitw) => match bitw {
                8 => {
                    if matches!(out_fill, RegFill::Undefined | RegFill::Zeroed) {
                        IcedInst::with2(Code::Movzx_r32_rm8, outr.to_reg32(), memop)
                    } else {
                        assert_matches!(out_fill, RegFill::Signed);
                        IcedInst::with2(Code::Movsx_r64_rm8, outr.to_reg64(), memop)
                    }
                }
                16 => {
                    if matches!(out_fill, RegFill::Undefined | RegFill::Zeroed) {
                        IcedInst::with2(Code::Movzx_r32_rm16, outr.to_reg32(), memop)
                    } else {
                        assert_matches!(out_fill, RegFill::Signed);
                        IcedInst::with2(Code::Movsx_r64_rm16, outr.to_reg64(), memop)
                    }
                }
                32 => {
                    if matches!(out_fill, RegFill::Undefined | RegFill::Zeroed) {
                        IcedInst::with2(Code::Mov_r32_rm32, outr.to_reg32(), memop)
                    } else {
                        assert_matches!(out_fill, RegFill::Signed);
                        IcedInst::with2(Code::Movsxd_r64_rm32, outr.to_reg64(), memop)
                    }
                }
                64 => IcedInst::with2(Code::Mov_r64_rm64, outr.to_reg64(), memop),
                x => todo!("{x}"),
            },
            Ty::Ptr(_) => IcedInst::with2(Code::Mov_r64_rm64, outr.to_reg64(), memop),
            _ => unreachable!(),
        });
        Ok(())
    }

    fn _i_store_float(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Store {
            ptr,
            val,
            is_volatile: _,
        }: &Store,
    ) -> Result<(), CompilationError> {
        assert_matches!(b.inst_ty(self.m, *val), Ty::Double | Ty::Float);
        let (ptr, off) = self.flatten_ptradd_chain(b, *ptr).unwrap_or((*ptr, 0));
        let [ptrr, valr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: ptr,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::Input {
                    in_iidx: *val,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    clobber: false,
                },
            ],
        )?;
        let memop = if off == 0 {
            MemoryOperand::with_base(ptrr.to_reg64())
        } else {
            MemoryOperand::with_base_displ(ptrr.to_reg64(), off)
        };

        self.asm.push_inst(match b.inst_ty(self.m, *val) {
            Ty::Double => IcedInst::with2(Code::Movsd_xmmm64_xmm, memop, valr.to_xmm()),
            Ty::Float => IcedInst::with2(Code::Movss_xmmm32_xmm, memop, valr.to_xmm()),
            _ => unreachable!(),
        });

        Ok(())
    }

    fn i_store_intptr(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Store {
            ptr,
            val,
            is_volatile: _,
        }: &Store,
    ) -> Result<(), CompilationError> {
        assert_matches!(b.inst_ty(self.m, *val), Ty::Int(_) | Ty::Ptr(0));

        let val_bitw = b.inst_bitw(self.m, *val);
        let (ptr, off) = self.flatten_ptradd_chain(b, *ptr).unwrap_or((*ptr, 0));

        // Try to optimise load-add-const-store sequences such as:
        // ```
        // %85: i64 = load %44
        // %87: i64 = 79
        // %88: i64 = add %_, %87
        // store %88, %44
        // ```
        if let Inst::Add(Add { lhs, rhs, .. }) = b.inst(*val)
            && let Some(imm) = self.sign_ext_op_for_imm32(b, *rhs)
            && let Inst::Load(Load {
                ptr: load_ptr,
                is_volatile: false,
                ..
            }) = b.inst(*lhs)
        {
            let (load_ptr, load_off) = self
                .flatten_ptradd_chain(b, *load_ptr)
                .unwrap_or((*load_ptr, 0));
            if (ptr, off) == (load_ptr, load_off) && !b.heap_effects_on(*lhs, *lhs + 1..iidx) {
                let [ptrr] = ra.alloc(
                    self,
                    iidx,
                    [RegCnstr::Input {
                        in_iidx: ptr,
                        in_fill: RegCnstrFill::Undefined,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    }],
                )?;
                let memop = MemoryOperand::with_base_displ(ptrr.to_reg64(), off);
                self.asm.push_inst(match val_bitw {
                    8 => {
                        assert_eq!(i32::from(i8::try_from(imm).unwrap()), imm);
                        IcedInst::with2(Code::Add_rm8_imm8, memop, imm)
                    }
                    16 => {
                        assert_eq!(i32::from(i16::try_from(imm).unwrap()), imm);
                        IcedInst::with2(Code::Add_rm16_imm16, memop, imm)
                    }
                    32 => IcedInst::with2(Code::Add_rm32_imm32, memop, imm),
                    64 => IcedInst::with2(Code::Add_rm64_imm32, memop, imm),
                    x => todo!("{x}"),
                });
                return Ok(());
            }
        }

        if let Some(imm) = self.sign_ext_op_for_imm32(b, *val) {
            let [ptrr] = ra.alloc(
                self,
                iidx,
                [RegCnstr::Input {
                    in_iidx: ptr,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                }],
            )?;
            let memop = if off == 0 {
                MemoryOperand::with_base(ptrr.to_reg64())
            } else {
                MemoryOperand::with_base_displ(ptrr.to_reg64(), off)
            };

            self.asm.push_inst(match val_bitw {
                8 => IcedInst::with2(Code::Mov_rm8_imm8, memop, imm),
                16 => IcedInst::with2(Code::Mov_rm16_imm16, memop, imm),
                32 => IcedInst::with2(Code::Mov_rm32_imm32, memop, imm),
                64 => IcedInst::with2(Code::Mov_rm64_imm32, memop, imm),
                x => todo!("{x}"),
            });
        } else {
            let [ptrr, valr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::Input {
                        in_iidx: ptr,
                        in_fill: RegCnstrFill::Undefined,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                    RegCnstr::Input {
                        in_iidx: *val,
                        in_fill: RegCnstrFill::Undefined,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                ],
            )?;
            let memop = if off == 0 {
                MemoryOperand::with_base(ptrr.to_reg64())
            } else {
                MemoryOperand::with_base_displ(ptrr.to_reg64(), off)
            };

            self.asm.push_inst(match val_bitw {
                8 => IcedInst::with2(Code::Mov_rm8_r8, memop, valr.to_reg8()),
                16 => IcedInst::with2(Code::Mov_rm16_r16, memop, valr.to_reg16()),
                32 => IcedInst::with2(Code::Mov_rm32_r32, memop, valr.to_reg32()),
                64 => IcedInst::with2(Code::Mov_rm64_r64, memop, valr.to_reg64()),
                x => todo!("{x}"),
            });
        }

        Ok(())
    }
}

impl HirToAsmBackend for X64HirToAsm<'_> {
    type Label = LabelIdx;
    type Reg = Reg;

    #[cfg(test)]
    type BuildTest = String;

    fn smp_to_vloc(smp_locs: &SmallVec<[yksmp::Location; 1]>) -> VarLocs<Self::Reg> {
        use yksmp::Location as L;
        assert_eq!(smp_locs.len(), 1, "Multi-locations not yet supported");
        match &smp_locs[0] {
            L::Register(dwarf_reg, _sz, extras) => {
                let mut out = smallvec![VarLoc::Reg(Reg::from_dwarf_reg(*dwarf_reg))];
                for x in extras {
                    if *x >= 0 {
                        out.push(VarLoc::Reg(Reg::from_dwarf_reg(x.cast_unsigned())));
                    } else {
                        out.push(VarLoc::Stack(u32::from(x.unsigned_abs())));
                    }
                }
                VarLocs::new(out)
            }
            L::Direct(6, off, _sz) => {
                assert!(*off <= 0);
                VarLocs::new(smallvec![VarLoc::StackOff(off.unsigned_abs())])
            }
            L::Indirect(6, off, _sz) => {
                assert!(*off <= 0);
                VarLocs::new(smallvec![VarLoc::Stack(off.unsigned_abs())])
            }
            x => {
                todo!("{:?}", x);
            }
        }
    }

    fn thread_local_off(addr: *const c_void) -> u32 {
        let mut fsaddr: *mut c_void;
        unsafe {
            std::arch::asm!(
                "mov {fsaddr}, fs:0",
                fsaddr = out(reg) fsaddr,
            );
        }
        let off = unsafe { fsaddr.offset_from(addr) };
        assert!(off > 0);
        u32::try_from(off).unwrap()
    }

    fn iter_possible_regs(&self, b: &Block, iidx: InstIdx) -> impl Iterator<Item = Self::Reg> {
        match b.inst_ty(self.m, iidx) {
            Ty::Double | Ty::Float => ALL_XMM_REGS.iter().cloned(),
            Ty::Func(_func_ty) => todo!(),
            Ty::Int(_) | Ty::Ptr(_) => NORMAL_GP_REGS.iter().cloned(),
            Ty::Void => todo!(),
        }
    }

    fn body_completed(&mut self, label: Option<Self::Label>, stack_off: u32) {
        let stack_off = i32::try_from(stack_off).unwrap();
        if let Some(label) = label {
            self.asm.attach_label(label);
        }
        self.asm.push_inst(IcedInst::with2(
            Code::Sub_rm64_imm32,
            IcedReg::RSP,
            stack_off.next_multiple_of(16),
        ));
        self.asm.block_completed();
    }

    #[allow(clippy::fn_to_numeric_cast)]
    fn guard_end(
        &mut self,
        _ra: &mut RegAlloc<Self>,
        _b: &Block,
        trid: TraceId,
        gridx: GuardRestoreIdx,
    ) -> Result<LabelIdx, CompilationError> {
        self.asm
            .push_inst(IcedInst::with1(Code::Call_rm64, IcedReg::RAX));
        self.asm.push_inst(IcedInst::with2(
            Code::Mov_r64_imm64,
            IcedReg::RAX,
            // This cast is fine on x64, and this module will only be compiled on that platform.
            super::deopt::__yk_j2_deopt as i64,
        ));
        self.asm.push_inst(IcedInst::with2(
            Code::Mov_r32_imm32,
            IcedReg::EDX,
            i32::try_from(usize::from(gridx)).unwrap(),
        ));
        self.asm.push_inst(IcedInst::with2(
            Code::Mov_r64_imm64,
            IcedReg::RSI,
            trid.as_u64().cast_signed(),
        ));
        self.asm.push_inst(IcedInst::with2(
            Code::Mov_rm64_r64,
            IcedReg::RDI,
            IcedReg::RBP,
        ));

        // This is the "dummy" jump that we will modify if a side-trace is created.
        let patch_label = self.asm.mk_label();
        let dummy_label = self.asm.mk_label();
        self.asm.attach_label(dummy_label);
        self.asm.push_reloc(
            IcedInst::with_branch(Code::Jmp_rel32_64, 0),
            RelocKind::RipRelativeWithLabel(dummy_label),
        );
        self.asm.attach_label(patch_label);

        Ok(patch_label)
    }

    fn guard_completed(
        &mut self,
        entry_label: Self::Label,
        patch_label: Self::Label,
        extra_stack_len: u32,
        bid: aot_ir::BBlockId,
        deopt_frames: SmallVec<[DeoptFrame<Self::Reg>; 1]>,
        switch: Option<Switch>,
    ) {
        let stack_off = i32::try_from(extra_stack_len).unwrap();
        self.asm.push_inst(IcedInst::with2(
            Code::Sub_rm64_imm32,
            IcedReg::RSP,
            stack_off.next_multiple_of(16),
        ));

        self.asm.attach_label(entry_label);
        self.asm.block_completed();

        self.guards.push(IntermediateGuard {
            patch_label,
            bid,
            deopt_frames,
            extra_stack_len,
            switch,
        });
    }

    fn build_exe(
        mut self,
        log: bool,
        labels: &[Self::Label],
    ) -> Result<
        (
            *mut c_void,
            IndexVec<GuardRestoreIdx, J2CompiledGuard<Reg>>,
            Option<String>,
            Vec<usize>,
        ),
        CompilationError,
    > {
        // Push the data section as its own block. This rests on the assumption that the start of
        // each block is aligned.
        let mut data_off = BLOCK_ALIGNMENT;
        for (data, (align, lidx)) in self.data_sec.into_iter() {
            if !data_off.is_multiple_of(usize::try_from(align).unwrap()) {
                todo!();
            }
            self.asm.push_inst(IcedInst::with_declare_byte(&data));
            self.asm.attach_label(lidx);
            data_off += data.len();
        }
        self.asm.block_completed();

        // Merge all labels into one vec as that's what `asm.into_exe` prefers.
        let all_labels = labels
            .iter()
            .chain(
                self.guards
                    .iter()
                    .map(|IntermediateGuard { patch_label, .. }| patch_label),
            )
            .cloned()
            .collect::<Vec<_>>();

        let (buf, log, mut label_offs) = self.asm.into_exe(log, all_labels.as_slice())?;

        // Demerge the label offsets.
        let guard_labels = label_offs.split_off(labels.len());
        assert_eq!(guard_labels.len(), self.guards.len());
        assert_eq!(label_offs.len(), labels.len());

        // Convert [IntermediateGuard]s into [J2CompiledGuard]s.
        let guards = self
            .guards
            .into_iter()
            .zip(guard_labels)
            .map(
                |(
                    IntermediateGuard {
                        bid,
                        deopt_frames,
                        extra_stack_len,
                        switch,
                        ..
                    },
                    patch_off,
                )| {
                    J2CompiledGuard::new(
                        bid,
                        deopt_frames,
                        u32::try_from(patch_off).unwrap(),
                        extra_stack_len,
                        switch,
                    )
                },
            )
            .collect::<IndexVec<_, _>>();

        Ok((buf, guards, log, label_offs))
    }

    #[cfg(test)]
    fn build_test(self, labels: &[Self::Label]) -> Self::BuildTest {
        self.build_exe(true, labels).unwrap().2.unwrap()
    }

    fn log(&mut self, s: String) {
        self.asm.log(s);
    }

    fn loop_backwards_jump(&mut self) -> Result<Self::Label, CompilationError> {
        let label = self.asm.mk_label();
        self.asm.push_reloc(
            IcedInst::with_branch(Code::Jmp_rel32_64, 0),
            RelocKind::RipRelativeWithLabel(label),
        );
        Ok(label)
    }

    fn sidetrace_end(
        &mut self,
        ctr: &Arc<J2CompiledTrace<Self::Reg>>,
    ) -> Result<(), CompilationError> {
        let addr = match &ctr.kind {
            J2CompiledTraceKind::Loop {
                entry_safepoint: _,
                entry_vlocs: _,
                stack_off: _,
                sidetrace_off,
            } => unsafe { ctr.exe().byte_add(*sidetrace_off) },
            J2CompiledTraceKind::Side { .. } => todo!(),
            #[cfg(test)]
            J2CompiledTraceKind::Test => unreachable!(),
        };
        self.asm.push_reloc(
            IcedInst::with_branch(Code::Jmp_rel32_64, 0),
            RelocKind::BranchWithAddr(addr.addr()),
        );
        Ok(())
    }

    fn const_needs_tmp_reg(&self, _reg: Reg, c: &ConstKind) -> Option<impl Iterator<Item = Reg>> {
        match c {
            ConstKind::Double(_) | ConstKind::Float(_) => Some(NORMAL_GP_REGS.iter().cloned()),
            ConstKind::Int(_) | ConstKind::Ptr(_) => None,
        }
    }

    fn move_const(
        &mut self,
        reg: Reg,
        tmp_reg: Option<Self::Reg>,
        tgt_bitw: u32,
        tgt_fill: RegFill,
        kind: &ConstKind,
    ) -> Result<(), CompilationError> {
        match kind {
            ConstKind::Double(x) => {
                let tmp_reg = tmp_reg.unwrap();
                assert!(tmp_reg.is_gp());
                self.asm.push_inst(IcedInst::with2(
                    Code::Movq_xmm_rm64,
                    reg.to_xmm(),
                    tmp_reg.to_reg64(),
                ));
                self.asm.push_inst(IcedInst::with2(
                    Code::Mov_r64_imm64,
                    tmp_reg.to_reg64(),
                    x.to_bits().cast_signed(),
                ));
            }
            ConstKind::Float(x) => {
                let tmp_reg = tmp_reg.unwrap();
                assert!(tmp_reg.is_gp());
                self.asm.push_inst(IcedInst::with2(
                    Code::Movd_xmm_rm32,
                    reg.to_xmm(),
                    tmp_reg.to_reg32(),
                ));
                self.asm.push_inst(IcedInst::with2(
                    Code::Mov_r32_imm32,
                    tmp_reg.to_reg32(),
                    x.to_bits().cast_signed(),
                ));
            }
            ConstKind::Int(x) => {
                assert!(tmp_reg.is_none());
                assert!(tgt_bitw >= x.bitw());
                self.asm.push_inst(
                    if tgt_fill == RegFill::Undefined || tgt_fill == RegFill::Zeroed {
                        match tgt_bitw {
                            1..=32 => {
                                if let Some(x) = x.to_zero_ext_u32() {
                                    IcedInst::with2(Code::Mov_r32_imm32, reg.to_reg32(), x)
                                } else {
                                    todo!();
                                }
                            }
                            64 => {
                                if let Some(x) = x.to_zero_ext_u32() {
                                    IcedInst::with2(Code::Mov_rm32_imm32, reg.to_reg32(), x)
                                } else if let Some(x) = x.to_zero_ext_u64() {
                                    IcedInst::with2(Code::Mov_r64_imm64, reg.to_reg64(), x)
                                } else {
                                    todo!();
                                }
                            }
                            x => todo!("{x}"),
                        }
                    } else {
                        assert_eq!(tgt_fill, RegFill::Signed);
                        if let Some(x) = x.to_sign_ext_i32() {
                            IcedInst::with2(Code::Mov_rm64_imm32, reg.to_reg64(), x)
                        } else {
                            todo!();
                        }
                    },
                );
            }
            ConstKind::Ptr(x) => {
                assert!(tmp_reg.is_none());
                assert_ne!(tgt_fill, RegFill::Signed);
                assert_eq!(tgt_bitw, 64);
                self.asm.push_inst(IcedInst::with2(
                    Code::Mov_r64_imm64,
                    reg.to_reg64(),
                    u64::try_from(*x).unwrap(),
                ));
            }
        }
        Ok(())
    }

    fn move_stackoff(&mut self, reg: Self::Reg, stack_off: u32) -> Result<(), CompilationError> {
        self.asm.push_inst(IcedInst::with2(
            Code::Lea_r64_m,
            reg.to_reg64(),
            MemoryOperand::with_base_displ(IcedReg::RBP, -i64::from(stack_off)),
        ));
        Ok(())
    }

    fn arrange_fill(&mut self, reg: Reg, src_fill: RegFill, dst_bitw: u32, dst_fill: RegFill) {
        match (src_fill, dst_fill) {
            (RegFill::Undefined, RegFill::Undefined) => (),
            (RegFill::Undefined | RegFill::Signed, RegFill::Zeroed) => match dst_bitw {
                1..=31 => {
                    self.asm.push_inst(IcedInst::with2(
                        Code::And_rm32_imm32,
                        reg.to_reg32(),
                        ((1u64 << dst_bitw) - 1) as i32,
                    ));
                }
                32 => {
                    self.asm.push_inst(IcedInst::with2(
                        Code::Mov_r32_rm32,
                        reg.to_reg32(),
                        reg.to_reg32(),
                    ));
                }
                64 => (),
                x => todo!("{x}"),
            },
            (RegFill::Zeroed, RegFill::Undefined) => (),
            (RegFill::Zeroed, RegFill::Zeroed) => (),
            (RegFill::Undefined | RegFill::Zeroed, RegFill::Signed) => match dst_bitw {
                1 => {
                    self.asm
                        .push_inst(IcedInst::with1(Code::Neg_rm64, reg.to_reg64()));
                    self.asm
                        .push_inst(IcedInst::with2(Code::And_rm32_imm8, reg.to_reg32(), 1));
                }
                8 => self.asm.push_inst(IcedInst::with2(
                    Code::Movsx_r64_rm8,
                    reg.to_reg64(),
                    reg.to_reg8(),
                )),
                16 => self.asm.push_inst(IcedInst::with2(
                    Code::Movsx_r64_rm16,
                    reg.to_reg64(),
                    reg.to_reg16(),
                )),
                32 => self.asm.push_inst(IcedInst::with2(
                    Code::Movsxd_r64_rm32,
                    reg.to_reg64(),
                    reg.to_reg32(),
                )),
                64 => (),
                x => todo!("{x}"),
            },
            (RegFill::Signed, RegFill::Undefined) => (),
            (RegFill::Signed, RegFill::Signed) => (),
        }
    }

    fn copy_reg(&mut self, from_reg: Self::Reg, to_reg: Self::Reg) -> Result<(), CompilationError> {
        assert!(
            (from_reg.is_gp() && to_reg.is_gp()) || (from_reg.is_fp() && to_reg.is_fp()),
            "{from_reg:?} {to_reg:?}"
        );
        if from_reg.is_gp() {
            self.asm.push_inst(IcedInst::with2(
                Code::Mov_r64_rm64,
                to_reg.to_reg64(),
                from_reg.to_reg64(),
            ));
        } else {
            assert!(from_reg.is_fp());
            self.asm.push_inst(IcedInst::with2(
                Code::Movsd_xmm_xmmm64,
                to_reg.to_xmm(),
                from_reg.to_xmm(),
            ));
        }
        Ok(())
    }

    fn align_spill(&self, stack_off: u32, bitw: u32) -> u32 {
        match bitw {
            1..=8 => stack_off + 1,
            9..=16 => (stack_off + 2).next_multiple_of(2),
            17..=32 => (stack_off + 4).next_multiple_of(4),
            33..=64 => (stack_off + 8).next_multiple_of(8),
            x => todo!("{x}"),
        }
    }

    fn spill(
        &mut self,
        reg: Reg,
        in_fill: RegFill,
        stack_off: u32,
        bitw: u32,
    ) -> Result<(), CompilationError> {
        let mop = MemoryOperand::with_base_displ(IcedReg::RBP, -i64::from(stack_off));
        if reg.is_gp() {
            match bitw {
                1 => {
                    if in_fill == RegFill::Zeroed {
                        self.asm
                            .push_inst(IcedInst::with2(Code::Mov_rm8_r8, mop, reg.to_reg8()))
                    } else {
                        self.asm.push_inst(IcedInst::with1(Code::Setb_rm8, mop));
                        self.asm
                            .push_inst(IcedInst::with2(Code::Bt_rm32_imm8, reg.to_reg32(), 0))
                    }
                }
                8 => self.asm.push_inst(IcedInst::with2(
                    Code::Mov_rm8_r8,
                    MemoryOperand::with_base_displ(IcedReg::RBP, -i64::from(stack_off)),
                    reg.to_reg8(),
                )),
                16 => self.asm.push_inst(IcedInst::with2(
                    Code::Mov_rm16_r16,
                    MemoryOperand::with_base_displ(IcedReg::RBP, -i64::from(stack_off)),
                    reg.to_reg16(),
                )),
                32 => self.asm.push_inst(IcedInst::with2(
                    Code::Mov_rm32_r32,
                    MemoryOperand::with_base_displ(IcedReg::RBP, -i64::from(stack_off)),
                    reg.to_reg32(),
                )),
                64 => self.asm.push_inst(IcedInst::with2(
                    Code::Mov_rm64_r64,
                    MemoryOperand::with_base_displ(IcedReg::RBP, -i64::from(stack_off)),
                    reg.to_reg64(),
                )),
                x => todo!("{x}"),
            }
        } else {
            assert!(reg.is_fp());
            self.asm.push_inst(match bitw {
                64 => IcedInst::with2(Code::Movsd_xmmm64_xmm, mop, reg.to_xmm()),
                32 => IcedInst::with2(Code::Movss_xmmm32_xmm, mop, reg.to_xmm()),
                x => todo!("{x}"),
            })
        }
        Ok(())
    }

    fn unspill(
        &mut self,
        stack_off: u32,
        reg: Self::Reg,
        out_fill: RegFill,
        bitw: u32,
    ) -> Result<(), CompilationError> {
        let memop = MemoryOperand::with_base_displ(IcedReg::RBP, -i64::from(stack_off));
        if reg.is_gp() {
            self.asm.push_inst(match bitw {
                1..=8 => match out_fill {
                    RegFill::Undefined | RegFill::Zeroed => {
                        IcedInst::with2(Code::Movzx_r32_rm8, reg.to_reg32(), memop)
                    }
                    RegFill::Signed => match bitw {
                        8 => IcedInst::with2(Code::Movsx_r64_rm8, reg.to_reg64(), memop),
                        x => todo!("{x}"),
                    },
                },
                16 => match out_fill {
                    RegFill::Undefined | RegFill::Zeroed => {
                        IcedInst::with2(Code::Movzx_r32_rm16, reg.to_reg32(), memop)
                    }
                    RegFill::Signed => IcedInst::with2(Code::Movsx_r64_rm16, reg.to_reg64(), memop),
                },
                32 => match out_fill {
                    RegFill::Undefined | RegFill::Zeroed => {
                        IcedInst::with2(Code::Mov_r32_rm32, reg.to_reg32(), memop)
                    }
                    RegFill::Signed => {
                        IcedInst::with2(Code::Movsxd_r64_rm32, reg.to_reg64(), memop)
                    }
                },
                64 => match out_fill {
                    RegFill::Undefined | RegFill::Zeroed => {
                        IcedInst::with2(Code::Mov_r64_rm64, reg.to_reg64(), memop)
                    }
                    RegFill::Signed => {
                        assert_eq!(bitw, 64);
                        IcedInst::with2(Code::Mov_r64_rm64, reg.to_reg64(), memop)
                    }
                },
                x => todo!("{x}"),
            });
        } else {
            assert!(reg.is_fp());
            self.asm.push_inst(match bitw {
                64 => IcedInst::with2(Code::Movsd_xmm_xmmm64, reg.to_xmm(), memop),
                32 => IcedInst::with2(Code::Movss_xmm_xmmm32, reg.to_xmm(), memop),
                x => todo!("{x}"),
            });
        }
        Ok(())
    }

    fn i_abs(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Abs {
            tyidx: _,
            val: src,
            is_int_min_poison: _,
        }: &Abs,
    ) -> Result<(), CompilationError> {
        let bitw = b.inst_bitw(self.m, iidx);
        let [ior, tmpr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::InputOutput {
                    in_iidx: *src,
                    in_fill: RegCnstrFill::Signed,
                    out_fill: RegCnstrFill::Signed,
                    regs: &NORMAL_GP_REGS,
                },
                RegCnstr::Temp {
                    regs: &NORMAL_GP_REGS,
                },
            ],
        )?;

        match bitw {
            64 => {
                self.asm.push_inst(IcedInst::with2(
                    Code::Cmovl_r64_rm64,
                    ior.to_reg64(),
                    tmpr.to_reg64(),
                ));
                self.asm
                    .push_inst(IcedInst::with1(Code::Neg_rm64, ior.to_reg64()));
                self.asm.push_inst(IcedInst::with2(
                    Code::Mov_r64_rm64,
                    tmpr.to_reg64(),
                    ior.to_reg64(),
                ));
            }
            x => todo!("{x}"),
        }
        Ok(())
    }

    fn i_add(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Add {
            tyidx: _,
            lhs,
            rhs,
            nuw,
            nsw,
        }: &Add,
    ) -> Result<(), CompilationError> {
        // We don't handle nuw or nsw yet.
        assert!(!*nuw && !*nsw);

        let bitw = b.inst_bitw(self.m, *lhs);
        assert_eq!(bitw, b.inst_bitw(self.m, *rhs));
        let out_fill = match bitw {
            32 | 64 => RegCnstrFill::Zeroed,
            _ => RegCnstrFill::Undefined,
        };
        if let Some(imm) = self.sign_ext_op_for_imm32(b, *rhs) {
            let [lhsr] = ra.alloc(
                self,
                iidx,
                [RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Undefined,
                    out_fill,
                    regs: &NORMAL_GP_REGS,
                }],
            )?;
            self.asm.push_inst(match bitw {
                1..=32 => IcedInst::with2(Code::Add_rm32_imm32, lhsr.to_reg32(), imm),
                64 => IcedInst::with2(Code::Add_rm64_imm32, lhsr.to_reg64(), imm),
                x => todo!("{x}"),
            });
        } else {
            let [lhsr, rhsr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::InputOutput {
                        in_iidx: *lhs,
                        in_fill: RegCnstrFill::Undefined,
                        out_fill,
                        regs: &NORMAL_GP_REGS,
                    },
                    RegCnstr::Input {
                        in_iidx: *rhs,
                        in_fill: RegCnstrFill::Undefined,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                ],
            )?;
            self.asm.push_inst(match bitw {
                1..=32 => IcedInst::with2(Code::Add_rm32_r32, lhsr.to_reg32(), rhsr.to_reg32()),
                64 => IcedInst::with2(Code::Add_rm64_r64, lhsr.to_reg64(), rhsr.to_reg64()),
                x => todo!("{x}"),
            });
        }

        Ok(())
    }

    fn i_and(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        And { tyidx: _, lhs, rhs }: &And,
    ) -> Result<(), CompilationError> {
        let bitw = b.inst_bitw(self.m, *lhs);
        let (imm, mut in_fill) = (
            self.zero_ext_op_for_imm32(b, bitw, *rhs),
            RegCnstrFill::Zeroed,
        );
        if bitw == 32 || bitw == 64 {
            // We can relax sign / zero fill for values that are exactly 32/64 bit.
            in_fill = RegCnstrFill::Undefined;
        }

        if let Some(imm) = imm {
            let [lhsr] = ra.alloc(
                self,
                iidx,
                [RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill,
                    out_fill: RegCnstrFill::Zeroed,
                    regs: &NORMAL_GP_REGS,
                }],
            )?;
            self.asm.push_inst(match bitw {
                1..=32 => IcedInst::with2(Code::And_rm32_imm32, lhsr.to_reg32(), imm),
                64 => IcedInst::with2(Code::And_rm64_imm32, lhsr.to_reg64(), imm),
                x => todo!("{x}"),
            });
        } else {
            todo!();
        }

        Ok(())
    }

    fn i_ashr(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        AShr {
            tyidx: _,
            lhs,
            rhs,
            exact,
        }: &AShr,
    ) -> Result<(), CompilationError> {
        // We don't handle `exact` yet.
        assert!(!*exact);

        // LLVM defines that a poison value is computed if one shifts by >= the bit width of the
        // first operand. This allows us to ignore a lot of seemingly necessary checks in the
        // below. For example we get away with using the 8-bit register `cl` because we don't
        // support any types bigger than 64 bits. If at runtime someone tries to shift a value
        // bigger than `cl` can express, then that's their problem!
        let bitw = b.inst_bitw(self.m, *lhs);
        if let Some(imm) = self.zero_ext_op_for_imm8(b, *rhs) {
            let [lhsr] = ra.alloc(
                self,
                iidx,
                [RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Signed,
                    out_fill: RegCnstrFill::Signed,
                    regs: &NORMAL_GP_REGS,
                }],
            )?;
            assert!(bitw <= 64);
            self.asm
                .push_inst(IcedInst::with2(Code::Sar_rm64_imm8, lhsr.to_reg64(), imm));
        } else {
            let [lhsr, rhsr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::InputOutput {
                        in_iidx: *lhs,
                        in_fill: RegCnstrFill::Signed,
                        out_fill: RegCnstrFill::Signed,
                        regs: &NORMAL_GP_REGS,
                    },
                    RegCnstr::Input {
                        in_iidx: *rhs,
                        in_fill: RegCnstrFill::Zeroed,
                        regs: &[Reg::RCX],
                        clobber: false,
                    },
                ],
            )?;
            assert!(bitw <= 64);
            self.asm.push_inst(IcedInst::with2(
                Code::Sar_rm64_CL,
                lhsr.to_reg64(),
                rhsr.to_reg8(),
            ));
        }
        Ok(())
    }

    fn i_call(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Call {
            tgt,
            func_tyidx,
            args,
        }: &Call,
    ) -> Result<(), CompilationError> {
        // Calls on x64 with the SysV ABI have complex requirements and fiddly optimisation
        // potential. Some GP registers have special meanings in some, but not necessarily all,
        // cases and some, but not all, GP registers are preserved across call. FP registers are
        // much simpler: there are no special meanings, and no FP registers are preserved across
        // calls.
        //
        // At a high-level, we build up constraints for every GP and FP register, starting them in
        // the `Clobber` constraint. We then add the constraints for inputs (phase 1). We then add
        // the constraints for outputs (phase 2), which also -- to optimise things as far as
        // possible -- means taking into account indirect function calls.

        // The GP registers we will clobber.
        //
        // NOTE! The order these are stored in is relied upon by `GP_CLOBBER_TMPS`, `RAX_OFF` and
        // `GP_ARGS`. Changing this order requires updating those variables too.
        const GP_CLOBBERS: [Reg; 9] = [
            Reg::RAX,
            Reg::RCX,
            Reg::RDX,
            Reg::RSI,
            Reg::RDI,
            Reg::R8,
            Reg::R9,
            Reg::R10,
            Reg::R11,
        ];
        // This is a sort-of-hack to assuage the borrow checker. The order of elements must exactly
        // match `GB_CLOBBERS`.
        const GP_CLOBBER_TMPS: [&[Reg]; 9] = [
            &[Reg::RAX],
            &[Reg::RCX],
            &[Reg::RDX],
            &[Reg::RSI],
            &[Reg::RDI],
            &[Reg::R8],
            &[Reg::R9],
            &[Reg::R10],
            &[Reg::R11],
        ];
        // What offset is `Reg::RAX` in `GP_CLOBBERS`?
        const RAX_OFF: usize = 0;
        // The order that GP parameters should be passed in: each entry is an offset into
        // `GP_CLOBBERS`.
        const GP_ARG_OFFS: [usize; 6] = [
            4, // RDI
            3, // RSI
            2, // RDX
            1, // RCX
            5, // R8
            6, // R9
        ];
        // This is a sort-of-hack to assuage the borrow checker.
        const FP_CLOBBER_TMPS: [&[Reg]; 16] = [
            &[Reg::XMM0],
            &[Reg::XMM1],
            &[Reg::XMM2],
            &[Reg::XMM3],
            &[Reg::XMM4],
            &[Reg::XMM5],
            &[Reg::XMM6],
            &[Reg::XMM7],
            &[Reg::XMM8],
            &[Reg::XMM9],
            &[Reg::XMM10],
            &[Reg::XMM11],
            &[Reg::XMM12],
            &[Reg::XMM13],
            &[Reg::XMM14],
            &[Reg::XMM15],
        ];

        // This will be `Some(addr)` (a) the function is a constant pointer (b) and is
        // representable as a near call.
        let fn_addr = b
            .inst_ptr(self.m, *tgt)
            .filter(|addr| self.asm.is_near_callable(*addr));

        let mut gp_cnstrs: [_; 9] = GP_CLOBBERS.map(|x| RegCnstr::Clobber { reg: x });
        // fp_cnstrs is stored in order `xmm0..=xmm15`. In particular, code below relies on
        // fp_cnstrs[0] being `xmm0` for return values.
        let mut fp_cnstrs: [_; 16] = ALL_XMM_REGS.map(|x| RegCnstr::Clobber { reg: x });

        // Phase 1: Deal with inputs.
        let mut fp_args_off = 0;
        let mut gp_args_iter = GP_ARG_OFFS.iter();
        for arg in args {
            let arg_ty = b.inst_ty(self.m, *arg);
            match arg_ty {
                Ty::Double | Ty::Float => {
                    debug_assert_matches!(fp_cnstrs[fp_args_off], RegCnstr::Clobber { .. });
                    fp_cnstrs[fp_args_off] = RegCnstr::Input {
                        in_iidx: *arg,
                        in_fill: RegCnstrFill::Undefined,
                        regs: FP_CLOBBER_TMPS[fp_args_off],
                        clobber: true,
                    };
                    fp_args_off += 1;
                }
                Ty::Func(_) => todo!(),
                Ty::Int(_) | Ty::Ptr(_) => {
                    let in_fill = match arg_ty {
                        Ty::Double | Ty::Float | Ty::Func(_) | Ty::Void => unreachable!(),
                        Ty::Int(_) | Ty::Ptr(_) => RegCnstrFill::Zeroed,
                    };
                    let gp_off = gp_args_iter.next().unwrap();
                    debug_assert_matches!(gp_cnstrs[*gp_off], RegCnstr::Clobber { .. });
                    gp_cnstrs[*gp_off] = RegCnstr::Input {
                        in_iidx: *arg,
                        in_fill,
                        regs: GP_CLOBBER_TMPS[*gp_off],
                        clobber: true,
                    };
                }
                Ty::Void => unreachable!(),
            }
        }

        // Phase 2: Deal with outputs. This is complicated by the fact that if we have an indirect
        // function call, we can often put that in RAX, and avoid splatting a separate register.
        let fty = self.m.func_ty(*func_tyidx);
        // This variable will end up with a [RegCnstr] for `tgt` iff (a) `fn_addr.is_none() ==
        // true` and (b) `fty.has_varargs == true`.
        let mut tgt_cnstr = None;
        match self.m.ty(fty.rtn_tyidx) {
            Ty::Double | Ty::Float => {
                match &fp_cnstrs[0] {
                    RegCnstr::Clobber { reg } => {
                        assert_eq!(*reg, Reg::XMM0);
                        fp_cnstrs[0] = RegCnstr::Output {
                            out_fill: RegCnstrFill::Undefined,
                            regs: FP_CLOBBER_TMPS[0],
                            can_be_same_as_input: false,
                        };
                    }
                    RegCnstr::Input {
                        in_iidx,
                        in_fill,
                        regs,
                        clobber: true,
                    } => {
                        fp_cnstrs[0] = RegCnstr::InputOutput {
                            in_iidx: *in_iidx,
                            in_fill: in_fill.clone(),
                            out_fill: RegCnstrFill::Undefined,
                            regs,
                        };
                    }
                    _ => unreachable!(),
                }
                if fn_addr.is_none() {
                    if !fty.has_varargs {
                        assert_matches!(gp_cnstrs[RAX_OFF], RegCnstr::Clobber { .. });
                        gp_cnstrs[RAX_OFF] = RegCnstr::Input {
                            in_iidx: *tgt,
                            in_fill: RegCnstrFill::Undefined,
                            regs: GP_CLOBBER_TMPS[RAX_OFF],
                            clobber: true,
                        };
                    } else {
                        tgt_cnstr = Some(RegCnstr::Input {
                            in_iidx: *tgt,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &NORMAL_GP_REGS,
                            clobber: true,
                        });
                    }
                }
            }
            Ty::Func(_func_ty) => todo!(),
            Ty::Int(_) | Ty::Ptr(_) => {
                debug_assert_matches!(gp_cnstrs[RAX_OFF], RegCnstr::Clobber { .. });
                if fn_addr.is_none() {
                    if !fty.has_varargs {
                        // RAX isn't used as an input for non-varargs functions.
                        assert_matches!(gp_cnstrs[RAX_OFF], RegCnstr::Clobber { .. });
                        gp_cnstrs[RAX_OFF] = RegCnstr::InputOutput {
                            in_iidx: *tgt,
                            in_fill: RegCnstrFill::Undefined,
                            out_fill: RegCnstrFill::Undefined,
                            regs: GP_CLOBBER_TMPS[RAX_OFF],
                        };
                    } else {
                        gp_cnstrs[RAX_OFF] = RegCnstr::Output {
                            out_fill: RegCnstrFill::Undefined,
                            regs: GP_CLOBBER_TMPS[RAX_OFF],
                            can_be_same_as_input: false,
                        };
                        tgt_cnstr = Some(RegCnstr::Input {
                            in_iidx: *tgt,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &NORMAL_GP_REGS,
                            clobber: true,
                        });
                    }
                } else {
                    gp_cnstrs[RAX_OFF] = RegCnstr::Output {
                        out_fill: RegCnstrFill::Undefined,
                        regs: GP_CLOBBER_TMPS[RAX_OFF],
                        can_be_same_as_input: false,
                    };
                }
            }
            Ty::Void => {
                if fn_addr.is_none() {
                    if !fty.has_varargs {
                        gp_cnstrs[RAX_OFF] = RegCnstr::Input {
                            in_iidx: *tgt,
                            in_fill: RegCnstrFill::Undefined,
                            regs: GP_CLOBBER_TMPS[RAX_OFF],
                            clobber: true,
                        };
                    } else {
                        tgt_cnstr = Some(RegCnstr::Input {
                            in_iidx: *tgt,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &NORMAL_GP_REGS,
                            clobber: true,
                        });
                    }
                }
            }
        }

        if fty.has_varargs {
            assert_matches!(
                gp_cnstrs[RAX_OFF],
                RegCnstr::Clobber { .. } | RegCnstr::Output { .. }
            );
        }

        // Phase 3: allocate registers and generate code.
        if let Some(fn_addr) = fn_addr {
            assert!(tgt_cnstr.is_none());
            let [..]: [_; GP_CLOBBERS.len() + ALL_XMM_REGS.len()] =
                ra.alloc(self, iidx, concat_arrays!(gp_cnstrs, fp_cnstrs))?;
            self.asm.push_reloc(
                IcedInst::with_branch(Code::Call_rel32_64, 0),
                RelocKind::NearCallWithAddr(fn_addr),
            );
        } else {
            assert!(fn_addr.is_none());
            let callr = if let Some(tgt_cnstr) = tgt_cnstr {
                assert_matches!(
                    tgt_cnstr,
                    RegCnstr::Input { .. } | RegCnstr::InputOutput { .. }
                );
                let [.., callr]: [_; GP_CLOBBERS.len() + ALL_XMM_REGS.len() + 1] = ra.alloc(
                    self,
                    iidx,
                    concat_arrays!(gp_cnstrs, fp_cnstrs, [tgt_cnstr]),
                )?;
                callr
            } else {
                assert!(tgt_cnstr.is_none());
                let [..]: [_; GP_CLOBBERS.len() + ALL_XMM_REGS.len()] =
                    ra.alloc(self, iidx, concat_arrays!(gp_cnstrs, fp_cnstrs))?;
                Reg::RAX
            };
            self.asm
                .push_inst(IcedInst::with1(Code::Call_rm64, callr.to_reg64()));
        }
        if fty.has_varargs {
            self.asm.push_inst(IcedInst::with2(
                Code::Mov_r32_imm32,
                IcedReg::EAX,
                u32::try_from(fp_args_off).unwrap(),
            ));
        }
        Ok(())
    }

    fn i_ctpop(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        CtPop { tyidx: _, val }: &CtPop,
    ) -> Result<(), CompilationError> {
        let bitw = b.inst_bitw(self.m, iidx);
        let [inr, outr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: *val,
                    in_fill: RegCnstrFill::Zeroed,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::Output {
                    out_fill: RegCnstrFill::Zeroed,
                    regs: &NORMAL_GP_REGS,
                    can_be_same_as_input: true,
                },
            ],
        )?;

        self.asm.push_inst(match bitw {
            32 => IcedInst::with2(Code::Popcnt_r32_rm32, outr.to_reg32(), inr.to_reg32()),
            64 => IcedInst::with2(Code::Popcnt_r64_rm64, outr.to_reg64(), inr.to_reg64()),
            x => todo!("{x}"),
        });
        Ok(())
    }

    fn i_dynptradd(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        DynPtrAdd {
            ptr,
            num_elems,
            elem_size,
        }: &DynPtrAdd,
    ) -> Result<(), CompilationError> {
        if let 1 | 2 | 4 | 8 = *elem_size {
            let [ptrr, nelemsr, outr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::Input {
                        in_iidx: *ptr,
                        in_fill: RegCnstrFill::Undefined,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                    RegCnstr::Input {
                        in_iidx: *num_elems,
                        in_fill: RegCnstrFill::Zeroed,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                    RegCnstr::Output {
                        out_fill: RegCnstrFill::Zeroed,
                        regs: &NORMAL_GP_REGS,
                        can_be_same_as_input: true,
                    },
                ],
            )?;
            self.asm.push_inst(IcedInst::with2(
                Code::Lea_r64_m,
                outr.to_reg64(),
                MemoryOperand::with_base_index_scale(
                    ptrr.to_reg64(),
                    nelemsr.to_reg64(),
                    *elem_size,
                ),
            ));
        } else {
            let [ptrr, nelemsr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::Input {
                        in_iidx: *ptr,
                        in_fill: RegCnstrFill::Undefined,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                    // It's more likely that `num_elems` will not be reused, so we make
                    // that the value we overwrite.
                    RegCnstr::InputOutput {
                        in_iidx: *num_elems,
                        in_fill: RegCnstrFill::Zeroed,
                        out_fill: RegCnstrFill::Zeroed,
                        regs: &NORMAL_GP_REGS,
                    },
                ],
            )?;
            // Add the result to the pointer. We make use of addition's commutative
            // property to reverse the "obvious" ordering of registers: doing so allows
            // us not to overwrite ptr_reg.
            self.asm.push_inst(IcedInst::with2(
                Code::Add_rm64_r64,
                nelemsr.to_reg64(),
                ptrr.to_reg64(),
            ));
            if elem_size.is_power_of_two() {
                self.asm.push_inst(IcedInst::with2(
                    Code::Shl_rm64_imm8,
                    nelemsr.to_reg64(),
                    i32::try_from(elem_size.ilog2()).unwrap(),
                ));
            } else {
                todo!();
            }
        }
        Ok(())
    }

    fn i_fadd(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        FAdd { tyidx, lhs, rhs }: &FAdd,
    ) -> Result<(), CompilationError> {
        let [lhsr, rhsr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Undefined,
                    out_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                },
                RegCnstr::Input {
                    in_iidx: *rhs,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    clobber: false,
                },
            ],
        )?;
        self.asm.push_inst(match self.m.ty(*tyidx) {
            Ty::Double => IcedInst::with2(Code::Addsd_xmm_xmmm64, lhsr.to_xmm(), rhsr.to_xmm()),
            Ty::Float => IcedInst::with2(Code::Addss_xmm_xmmm32, lhsr.to_xmm(), rhsr.to_xmm()),
            _ => panic!(),
        });

        Ok(())
    }

    fn i_fcmp(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        FCmp { pred, lhs, rhs }: &FCmp,
    ) -> Result<(), CompilationError> {
        // As per LLVM, some comparisons can be rewritten to equivalents that we can generate
        // better code for on x64. See `NeedSwap` in
        // https://github.com/llvm/llvm-project/blob/2b340c10a611d929fee25e6222909c8915e3d6b6/llvm/lib/Target/X86/X86InstrInfo.cpp#L3388
        let (pred, lhs, rhs) = match pred {
            FPred::Ugt => (FPred::Ult, rhs, lhs),
            FPred::Uge => (FPred::Ule, rhs, lhs),
            FPred::Olt => (FPred::Ogt, rhs, lhs),
            FPred::Ole => (FPred::Oge, rhs, lhs),
            _ => (*pred, lhs, rhs),
        };

        let bitw = b.inst_bitw(self.m, *lhs);
        let (lhsr, rhsr) = match pred {
            FPred::One | FPred::Oge | FPred::Ogt | FPred::Ueq | FPred::Ult | FPred::Ule => {
                let [lhsr, rhsr, outr] = ra.alloc(
                    self,
                    iidx,
                    [
                        RegCnstr::Input {
                            in_iidx: *lhs,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &ALL_XMM_REGS,
                            clobber: false,
                        },
                        RegCnstr::Input {
                            in_iidx: *rhs,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &ALL_XMM_REGS,
                            clobber: false,
                        },
                        RegCnstr::Output {
                            out_fill: RegCnstrFill::Undefined,
                            regs: &NORMAL_GP_REGS,
                            can_be_same_as_input: false,
                        },
                    ],
                )?;

                self.asm.push_inst(match pred {
                    FPred::One => IcedInst::with1(Code::Setne_rm8, outr.to_reg8()),
                    FPred::Oge => IcedInst::with1(Code::Setae_rm8, outr.to_reg8()),
                    FPred::Ogt => IcedInst::with1(Code::Seta_rm8, outr.to_reg8()),
                    FPred::Ueq => IcedInst::with1(Code::Sete_rm8, outr.to_reg8()),
                    FPred::Ult => IcedInst::with1(Code::Setb_rm8, outr.to_reg8()),
                    FPred::Ule => IcedInst::with1(Code::Setbe_rm8, outr.to_reg8()),
                    _ => unreachable!(),
                });
                (lhsr, rhsr)
            }
            FPred::Oeq | FPred::Une => {
                let [lhsr, rhsr, outr, tmpr] = ra.alloc(
                    self,
                    iidx,
                    [
                        RegCnstr::Input {
                            in_iidx: *lhs,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &ALL_XMM_REGS,
                            clobber: false,
                        },
                        RegCnstr::Input {
                            in_iidx: *rhs,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &ALL_XMM_REGS,
                            clobber: false,
                        },
                        RegCnstr::Output {
                            out_fill: RegCnstrFill::Undefined,
                            regs: &NORMAL_GP_REGS,
                            can_be_same_as_input: false,
                        },
                        RegCnstr::Temp {
                            regs: &NORMAL_GP_REGS,
                        },
                    ],
                )?;

                match pred {
                    FPred::Oeq => {
                        self.asm.push_inst(IcedInst::with2(
                            Code::And_rm8_r8,
                            outr.to_reg8(),
                            tmpr.to_reg8(),
                        ));
                        self.asm
                            .push_inst(IcedInst::with1(Code::Setnp_rm8, outr.to_reg8()));
                        self.asm
                            .push_inst(IcedInst::with1(Code::Sete_rm8, tmpr.to_reg8()));
                    }
                    FPred::Une => {
                        self.asm.push_inst(IcedInst::with2(
                            Code::Or_rm8_r8,
                            outr.to_reg8(),
                            tmpr.to_reg8(),
                        ));
                        self.asm
                            .push_inst(IcedInst::with1(Code::Setp_rm8, outr.to_reg8()));
                        self.asm
                            .push_inst(IcedInst::with1(Code::Setne_rm8, tmpr.to_reg8()));
                    }
                    _ => unreachable!(),
                }
                (lhsr, rhsr)
            }
            FPred::False | FPred::Ord | FPred::Uno | FPred::True => todo!(),
            FPred::Ugt | FPred::Uge | FPred::Olt | FPred::Ole => unreachable!(),
        };
        self.asm.push_inst(match bitw {
            64 => IcedInst::with2(Code::Ucomisd_xmm_xmmm64, lhsr.to_xmm(), rhsr.to_xmm()),
            32 => IcedInst::with2(Code::Ucomiss_xmm_xmmm32, lhsr.to_xmm(), rhsr.to_xmm()),
            x => todo!("{x}"),
        });
        Ok(())
    }

    fn i_fdiv(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        FDiv { tyidx, lhs, rhs }: &FDiv,
    ) -> Result<(), CompilationError> {
        let [lhsr, rhsr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Undefined,
                    out_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                },
                RegCnstr::Input {
                    in_iidx: *rhs,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    clobber: false,
                },
            ],
        )?;
        self.asm.push_inst(match self.m.ty(*tyidx) {
            Ty::Double => IcedInst::with2(Code::Divsd_xmm_xmmm64, lhsr.to_xmm(), rhsr.to_xmm()),
            Ty::Float => IcedInst::with2(Code::Divss_xmm_xmmm32, lhsr.to_xmm(), rhsr.to_xmm()),
            _ => panic!(),
        });

        Ok(())
    }

    fn i_fmul(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        FMul { tyidx, lhs, rhs }: &FMul,
    ) -> Result<(), CompilationError> {
        let [lhsr, rhsr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Undefined,
                    out_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                },
                RegCnstr::Input {
                    in_iidx: *rhs,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    clobber: false,
                },
            ],
        )?;
        self.asm.push_inst(match self.m.ty(*tyidx) {
            Ty::Double => IcedInst::with2(Code::Mulsd_xmm_xmmm64, lhsr.to_xmm(), rhsr.to_xmm()),
            Ty::Float => IcedInst::with2(Code::Mulss_xmm_xmmm32, lhsr.to_xmm(), rhsr.to_xmm()),
            _ => panic!(),
        });

        Ok(())
    }

    fn i_fsub(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        FSub { tyidx, lhs, rhs }: &FSub,
    ) -> Result<(), CompilationError> {
        let [lhsr, rhsr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Undefined,
                    out_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                },
                RegCnstr::Input {
                    in_iidx: *rhs,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    clobber: false,
                },
            ],
        )?;
        self.asm.push_inst(match self.m.ty(*tyidx) {
            Ty::Double => IcedInst::with2(Code::Subsd_xmm_xmmm64, lhsr.to_xmm(), rhsr.to_xmm()),
            Ty::Float => IcedInst::with2(Code::Subss_xmm_xmmm32, lhsr.to_xmm(), rhsr.to_xmm()),
            _ => panic!(),
        });

        Ok(())
    }

    fn i_fpext(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        FPExt { tyidx, val }: &FPExt,
    ) -> Result<(), CompilationError> {
        let [srcr, tgtr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: *val,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    clobber: false,
                },
                RegCnstr::Output {
                    out_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    can_be_same_as_input: true,
                },
            ],
        )?;

        self.asm
            .push_inst(match (b.inst_ty(self.m, *val), self.m.ty(*tyidx)) {
                (Ty::Float, Ty::Double) => {
                    IcedInst::with2(Code::Cvtss2sd_xmm_xmmm32, tgtr.to_xmm(), srcr.to_xmm())
                }
                _ => todo!(),
            });

        Ok(())
    }

    fn i_fptosi(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        FPToSI { tyidx, val }: &FPToSI,
    ) -> Result<(), CompilationError> {
        let [valr, outr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: *val,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    clobber: false,
                },
                RegCnstr::Output {
                    out_fill: RegCnstrFill::Zeroed,
                    regs: &NORMAL_GP_REGS,
                    can_be_same_as_input: false,
                },
            ],
        )?;

        let src_ty = b.inst_ty(self.m, *val);
        let dst_bitw = self.m.ty(*tyidx).bitw();
        self.asm.push_inst(match (src_ty, dst_bitw) {
            (Ty::Double, 32) => {
                IcedInst::with2(Code::Cvttsd2si_r32_xmmm64, outr.to_reg32(), valr.to_xmm())
            }
            (Ty::Double, 64) => {
                IcedInst::with2(Code::Cvttsd2si_r64_xmmm64, outr.to_reg64(), valr.to_xmm())
            }
            (Ty::Float, 32) => {
                IcedInst::with2(Code::Cvttss2si_r32_xmmm32, outr.to_reg32(), valr.to_xmm())
            }
            x => todo!("{x:?}"),
        });

        Ok(())
    }

    fn i_guard(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        ginst @ Guard {
            expect,
            cond,
            entry_vars,
            gridx,
            ..
        }: &Guard,
    ) -> Result<Self::Label, CompilationError> {
        if let Inst::ICmp(ICmp { .. }) = b.inst(*cond) {
            return self.i_icmp_guard(ra, b, iidx, ginst);
        }

        let [cndr, _] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: *cond,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::KeepAlive {
                    gridx: *gridx,
                    iidxs: entry_vars,
                },
            ],
        )?;

        let label = self.asm.mk_label();
        self.asm.push_reloc(
            if *expect {
                IcedInst::with_branch(Code::Jae_rel32_64, 0)
            } else {
                IcedInst::with_branch(Code::Jb_rel32_64, 0)
            },
            RelocKind::RipRelativeWithLabel(label),
        );
        self.asm
            .push_inst(IcedInst::with2(Code::Bt_rm32_imm8, cndr.to_reg32(), 0));

        Ok(label)
    }

    fn i_icmp(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        ICmp {
            pred,
            lhs,
            rhs,
            samesign: _,
        }: &ICmp,
    ) -> Result<(), CompilationError> {
        let c = match pred {
            IPred::Eq => Code::Sete_rm8,
            IPred::Ne => Code::Setne_rm8,
            IPred::Ugt => Code::Seta_rm8,
            IPred::Uge => Code::Setae_rm8,
            IPred::Ult => Code::Setb_rm8,
            IPred::Ule => Code::Setbe_rm8,
            IPred::Sgt => Code::Setg_rm8,
            IPred::Sge => Code::Setge_rm8,
            IPred::Slt => Code::Setl_rm8,
            IPred::Sle => Code::Setle_rm8,
        };

        let bitw = b.inst_bitw(self.m, *lhs);
        let (imm, mut in_fill) = if pred == &IPred::Eq {
            (self.sign_ext_op_for_imm32(b, *rhs), RegCnstrFill::Zeroed)
        } else if pred.is_signed() {
            (self.sign_ext_op_for_imm32(b, *rhs), RegCnstrFill::Signed)
        } else {
            (
                self.zero_ext_op_for_imm32(b, bitw, *rhs),
                RegCnstrFill::Zeroed,
            )
        };
        if bitw == 32 || bitw == 64 {
            // We can relax sign / zero fill for values that are exactly 32/64 bit.
            in_fill = RegCnstrFill::Undefined;
        }

        if let Some(imm) = imm {
            let [lhsr, outr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::Input {
                        in_iidx: *lhs,
                        in_fill,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                    RegCnstr::Output {
                        out_fill: RegCnstrFill::Undefined,
                        regs: &NORMAL_GP_REGS,
                        can_be_same_as_input: true,
                    },
                ],
            )?;
            self.asm.push_inst(IcedInst::with1(c, outr.to_reg8()));
            self.asm.push_inst(match bitw {
                1..=32 => IcedInst::with2(Code::Cmp_rm32_imm32, lhsr.to_reg32(), imm),
                64 => IcedInst::with2(Code::Cmp_rm64_imm32, lhsr.to_reg64(), imm),
                x => todo!("{x}"),
            });
        } else {
            let [lhsr, rhsr, outr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::Input {
                        in_iidx: *lhs,
                        in_fill: in_fill.clone(),
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                    RegCnstr::Input {
                        in_iidx: *rhs,
                        in_fill,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                    RegCnstr::Output {
                        out_fill: RegCnstrFill::Undefined,
                        regs: &NORMAL_GP_REGS,
                        can_be_same_as_input: true,
                    },
                ],
            )?;

            self.asm.push_inst(IcedInst::with1(c, outr.to_reg8()));
            self.asm.push_inst(match bitw {
                32 => IcedInst::with2(Code::Cmp_rm32_r32, lhsr.to_reg32(), rhsr.to_reg32()),
                64 => IcedInst::with2(Code::Cmp_rm64_r64, lhsr.to_reg64(), rhsr.to_reg64()),
                x => todo!("{x}"),
            });
        }

        Ok(())
    }

    fn i_inttoptr(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        IntToPtr { tyidx, val }: &IntToPtr,
    ) -> Result<(), CompilationError> {
        assert!(self.m.ty(*tyidx).bitw() <= 64);
        let out_fill = if self.m.ty(*tyidx).bitw() == 64 {
            RegCnstrFill::Zeroed
        } else {
            RegCnstrFill::Undefined
        };
        let [_] = ra.alloc(
            self,
            iidx,
            [RegCnstr::Cast {
                in_iidx: *val,
                out_fill,
                regs: &NORMAL_GP_REGS,
            }],
        )?;
        Ok(())
    }

    fn i_load(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        inst @ Load { tyidx, .. }: &Load,
    ) -> Result<(), CompilationError> {
        match self.m.ty(*tyidx) {
            Ty::Double | Ty::Float => self._i_load_float(ra, b, iidx, inst),
            Ty::Func(_) => todo!(),
            Ty::Int(_) | Ty::Ptr(_) => self._i_load_intptr(ra, b, iidx, inst),
            Ty::Void => unreachable!(),
        }
    }

    fn i_lshr(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        LShr {
            tyidx: _,
            lhs,
            rhs,
            exact,
        }: &LShr,
    ) -> Result<(), CompilationError> {
        assert!(!*exact);

        // LLVM defines that a poison value is computed if one shifts by >= the bit width of the
        // first operand. This allows us to ignore a lot of seemingly necessary checks in the
        // below. For example we get away with using the 8-bit register `cl` because we don't
        // support any types bigger than 64 bits. If at runtime someone tries to shift a value
        // bigger than `cl` can express, then that's their problem!
        let bitw = b.inst_bitw(self.m, *lhs);
        if let Some(imm) = self.zero_ext_op_for_imm8(b, *rhs) {
            let [lhsr] = ra.alloc(
                self,
                iidx,
                [RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Zeroed,
                    out_fill: RegCnstrFill::Zeroed,
                    regs: &NORMAL_GP_REGS,
                }],
            )?;
            self.asm.push_inst(match bitw {
                1..=32 => IcedInst::with2(Code::Shr_rm32_imm8, lhsr.to_reg32(), imm),
                33..=64 => IcedInst::with2(Code::Shr_rm64_imm8, lhsr.to_reg64(), imm),
                x => todo!("{x}"),
            });
        } else {
            let [lhsr, rhsr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::InputOutput {
                        in_iidx: *lhs,
                        in_fill: RegCnstrFill::Zeroed,
                        out_fill: RegCnstrFill::Zeroed,
                        regs: &NORMAL_GP_REGS,
                    },
                    RegCnstr::Input {
                        in_iidx: *rhs,
                        in_fill: RegCnstrFill::Zeroed,
                        regs: &[Reg::RCX],
                        clobber: false,
                    },
                ],
            )?;
            self.asm.push_inst(match bitw {
                1..=32 => IcedInst::with2(Code::Shr_rm32_CL, lhsr.to_reg32(), rhsr.to_reg8()),
                x => todo!("{x}"),
            });
        }
        Ok(())
    }

    fn i_mul(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Mul {
            tyidx: _,
            lhs,
            rhs,
            nuw,
            nsw,
        }: &Mul,
    ) -> Result<(), CompilationError> {
        // We don't handle nuw or nsw yet.
        assert!(!*nuw && !*nsw);

        let bitw = b.inst_bitw(self.m, *lhs);
        assert_eq!(bitw, b.inst_bitw(self.m, *rhs));
        let out_fill = match bitw {
            32 | 64 => RegCnstrFill::Zeroed,
            _ => RegCnstrFill::Undefined,
        };
        let [_lhsr, rhsr, _] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Zeroed,
                    out_fill,
                    regs: &[Reg::RAX],
                },
                RegCnstr::Input {
                    in_iidx: *rhs,
                    in_fill: RegCnstrFill::Zeroed,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                // Because we're dealing with unchecked multiply, the higher-order part of the
                // result in RDX is ignored.
                RegCnstr::Clobber { reg: Reg::RDX },
            ],
        )?;
        self.asm.push_inst(match bitw {
            1..=32 => IcedInst::with1(Code::Mul_rm32, rhsr.to_reg32()),
            64 => IcedInst::with1(Code::Mul_rm64, rhsr.to_reg64()),
            x => todo!("{x}"),
        });

        Ok(())
    }

    fn i_or(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Or {
            tyidx: _,
            lhs,
            rhs,
            disjoint,
        }: &Or,
    ) -> Result<(), CompilationError> {
        // We don't handle disjoint yet.
        assert!(!*disjoint);

        let bitw = b.inst_bitw(self.m, *lhs);
        assert_eq!(bitw, b.inst_bitw(self.m, *rhs));
        if let Some(imm) = self.zero_ext_op_for_imm32(b, bitw, *rhs) {
            let out_fill = match bitw {
                32 | 64 => RegCnstrFill::Zeroed,
                _ => RegCnstrFill::Undefined,
            };
            let [lhsr] = ra.alloc(
                self,
                iidx,
                [RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Undefined,
                    out_fill,
                    regs: &NORMAL_GP_REGS,
                }],
            )?;
            self.asm.push_inst(match bitw {
                1..=32 => IcedInst::with2(Code::Or_rm32_imm32, lhsr.to_reg32(), imm),
                x => todo!("{x}"),
            });
        } else {
            let out_fill = match bitw {
                32 | 64 => RegCnstrFill::Zeroed,
                _ => RegCnstrFill::Undefined,
            };
            let [lhsr, rhsr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::InputOutput {
                        in_iidx: *lhs,
                        in_fill: RegCnstrFill::Undefined,
                        out_fill,
                        regs: &NORMAL_GP_REGS,
                    },
                    RegCnstr::Input {
                        in_iidx: *rhs,
                        in_fill: RegCnstrFill::Undefined,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                ],
            )?;
            self.asm.push_inst(match bitw {
                1..=32 => IcedInst::with2(Code::Or_rm32_r32, lhsr.to_reg32(), rhsr.to_reg32()),
                x => todo!("{x}"),
            });
        }

        Ok(())
    }

    fn i_ptradd(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        PtrAdd {
            ptr,
            off,
            in_bounds,
            nusw,
            nuw,
        }: &PtrAdd,
    ) -> Result<(), CompilationError> {
        assert!(!in_bounds && !nusw && !nuw);
        let [ptrr, outr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: *ptr,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::Output {
                    out_fill: RegCnstrFill::Zeroed,
                    regs: &NORMAL_GP_REGS,
                    can_be_same_as_input: true,
                },
            ],
        )?;
        self.asm.push_inst(IcedInst::with2(
            Code::Lea_r64_m,
            outr.to_reg64(),
            MemoryOperand::with_base_displ(ptrr.to_reg64(), i64::from(*off)),
        ));
        Ok(())
    }

    fn i_ptrtoint(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        PtrToInt { tyidx, val }: &PtrToInt,
    ) -> Result<(), CompilationError> {
        assert!(self.m.ty(*tyidx).bitw() <= 64);
        let [_] = ra.alloc(
            self,
            iidx,
            [RegCnstr::Cast {
                in_iidx: *val,
                out_fill: RegCnstrFill::Zeroed,
                regs: &NORMAL_GP_REGS,
            }],
        )?;
        Ok(())
    }

    fn i_return(
        &mut self,
        _ra: &mut RegAlloc<Self>,
        _b: &Block,
        _iidx: InstIdx,
        Return { safepoint }: &Return,
    ) -> Result<(), CompilationError> {
        #[cfg(not(test))]
        let csrs = {
            let aot_smaps = AOT_STACKMAPS.as_ref().unwrap();
            let (_, prologue) = aot_smaps.get(usize::try_from(safepoint.id).unwrap());
            &prologue.csrs
        };

        #[cfg(test)]
        let csrs = {
            assert_eq!(safepoint.id, 0);
            [(3, -6), (12, -5), (13, -4), (14, -3), (15, -2)]
        };

        self.asm.push_inst(Ok(IcedInst::with(Code::Retnq)));
        self.asm
            .push_inst(IcedInst::with1(Code::Pop_r64, IcedReg::RBP));
        for (reg, _) in csrs.iter().rev() {
            self.asm.push_inst(IcedInst::with1(
                Code::Pop_r64,
                Reg::from_dwarf_reg(*reg).to_reg64(),
            ));
        }
        self.asm.push_inst(IcedInst::with2(
            Code::Sub_rm64_imm32,
            IcedReg::RSP,
            i32::try_from(csrs.len() * 8).unwrap(),
        ));
        self.asm.push_inst(IcedInst::with2(
            Code::Mov_r64_rm64,
            IcedReg::RSP,
            IcedReg::RBP,
        ));
        Ok(())
    }

    fn i_sdiv(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        SDiv {
            tyidx,
            lhs,
            rhs,
            exact,
        }: &SDiv,
    ) -> Result<(), CompilationError> {
        // We don't currently support `exact`.
        assert!(!*exact);
        let bitw = self.m.ty(*tyidx).bitw();
        let [_lhsr, rhsr, _] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Signed,
                    out_fill: RegCnstrFill::Signed,
                    regs: &[Reg::RAX],
                },
                RegCnstr::Input {
                    in_iidx: *rhs,
                    in_fill: RegCnstrFill::Signed,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::Clobber { reg: Reg::RDX },
            ],
        )?;
        assert_ne!(rhsr, Reg::RAX);
        assert_ne!(rhsr, Reg::RDX);
        assert!(bitw > 0 && bitw <= 64);
        self.asm
            .push_inst(IcedInst::with1(Code::Idiv_rm64, rhsr.to_reg64()));
        self.asm.push_inst(Ok(IcedInst::with(Code::Cqo)));
        Ok(())
    }

    fn i_select(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        Select {
            tyidx,
            cond,
            truev,
            falsev,
        }: &Select,
    ) -> Result<(), CompilationError> {
        match self.m.ty(*tyidx) {
            Ty::Double | Ty::Float => todo!(),
            Ty::Func(_) => todo!(),
            Ty::Int(bitw) => {
                let out_fill = if let 32 | 64 = bitw {
                    RegCnstrFill::Zeroed
                } else {
                    RegCnstrFill::Undefined
                };
                let [condr, truer, falser] = ra.alloc(
                    self,
                    iidx,
                    [
                        RegCnstr::Input {
                            in_iidx: *cond,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &NORMAL_GP_REGS,
                            clobber: false,
                        },
                        RegCnstr::InputOutput {
                            in_iidx: *truev,
                            in_fill: RegCnstrFill::Undefined,
                            out_fill,
                            regs: &NORMAL_GP_REGS,
                        },
                        RegCnstr::Input {
                            in_iidx: *falsev,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &NORMAL_GP_REGS,
                            clobber: false,
                        },
                    ],
                )?;
                self.asm.push_inst(match bitw {
                    1..=32 => {
                        IcedInst::with2(Code::Cmovae_r32_rm32, truer.to_reg32(), falser.to_reg32())
                    }
                    64 => {
                        IcedInst::with2(Code::Cmovae_r64_rm64, truer.to_reg64(), falser.to_reg64())
                    }
                    x => todo!("{x}"),
                });
                self.asm
                    .push_inst(IcedInst::with2(Code::Bt_rm32_imm8, condr.to_reg32(), 0));
                Ok(())
            }
            Ty::Ptr(addrspace) => {
                assert_eq!(*addrspace, 0);
                let [condr, truer, falser] = ra.alloc(
                    self,
                    iidx,
                    [
                        RegCnstr::Input {
                            in_iidx: *cond,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &NORMAL_GP_REGS,
                            clobber: false,
                        },
                        RegCnstr::InputOutput {
                            in_iidx: *truev,
                            in_fill: RegCnstrFill::Undefined,
                            out_fill: RegCnstrFill::Undefined,
                            regs: &NORMAL_GP_REGS,
                        },
                        RegCnstr::Input {
                            in_iidx: *falsev,
                            in_fill: RegCnstrFill::Undefined,
                            regs: &NORMAL_GP_REGS,
                            clobber: false,
                        },
                    ],
                )?;
                self.asm.push_inst(IcedInst::with2(
                    Code::Cmovae_r64_rm64,
                    truer.to_reg64(),
                    falser.to_reg64(),
                ));
                self.asm
                    .push_inst(IcedInst::with2(Code::Bt_rm32_imm8, condr.to_reg32(), 0));
                Ok(())
            }
            Ty::Void => todo!(),
        }
    }

    fn i_sext(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        SExt { val, .. }: &SExt,
    ) -> Result<(), CompilationError> {
        let [_] = ra.alloc(
            self,
            iidx,
            [RegCnstr::InputOutput {
                in_iidx: *val,
                in_fill: RegCnstrFill::Signed,
                out_fill: RegCnstrFill::Signed,
                regs: &NORMAL_GP_REGS,
            }],
        )?;
        Ok(())
    }

    fn i_shl(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Shl {
            tyidx: _,
            lhs,
            rhs,
            nuw,
            nsw,
        }: &Shl,
    ) -> Result<(), CompilationError> {
        // We don't handle nuw or nsw yet.
        assert!(!*nuw && !*nsw);

        let bitw = b.inst_bitw(self.m, *lhs);
        if let Some(imm) = self.zero_ext_op_for_imm8(b, *rhs) {
            let out_fill = match bitw {
                32 | 64 => RegCnstrFill::Zeroed,
                _ => RegCnstrFill::Undefined,
            };
            let [lhsr] = ra.alloc(
                self,
                iidx,
                [RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Undefined,
                    out_fill,
                    regs: &NORMAL_GP_REGS,
                }],
            )?;
            self.asm.push_inst(match bitw {
                64 => IcedInst::with2(Code::Shl_rm64_imm8, lhsr.to_reg64(), imm),
                32 => IcedInst::with2(Code::Shl_rm32_imm8, lhsr.to_reg32(), imm),
                x => todo!("{x}"),
            });
        } else {
            let [lhsr, rhsr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::InputOutput {
                        in_iidx: *lhs,
                        in_fill: RegCnstrFill::Zeroed,
                        out_fill: RegCnstrFill::Zeroed,
                        regs: &NORMAL_GP_REGS,
                    },
                    RegCnstr::Input {
                        in_iidx: *rhs,
                        in_fill: RegCnstrFill::Zeroed,
                        regs: &[Reg::RCX],
                        clobber: false,
                    },
                ],
            )?;
            self.asm.push_inst(match bitw {
                1..=32 => IcedInst::with2(Code::Shl_rm32_CL, lhsr.to_reg32(), rhsr.to_reg8()),
                x => todo!("{x}"),
            });
        }
        Ok(())
    }

    fn i_sitofp(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        SIToFP { tyidx, val }: &SIToFP,
    ) -> Result<(), CompilationError> {
        let [srcr, tgtr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: *val,
                    in_fill: RegCnstrFill::Signed,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::Output {
                    out_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    can_be_same_as_input: false,
                },
            ],
        )?;

        self.asm.push_inst(match self.m.ty(*tyidx) {
            Ty::Double => match b.inst_bitw(self.m, *val) {
                32 => IcedInst::with2(Code::Cvtsi2sd_xmm_rm32, tgtr.to_xmm(), srcr.to_reg32()),
                64 => IcedInst::with2(Code::Cvtsi2sd_xmm_rm64, tgtr.to_xmm(), srcr.to_reg64()),
                _ => todo!(),
            },
            Ty::Float => {
                assert_eq!(b.inst_bitw(self.m, *val), 32);
                IcedInst::with2(Code::Cvtsi2ss_xmm_rm32, tgtr.to_xmm(), srcr.to_reg32())
            }
            _ => unreachable!(),
        });
        Ok(())
    }

    fn i_smax(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        SMax { tyidx, lhs, rhs }: &SMax,
    ) -> Result<(), CompilationError> {
        let bitw = self.m.ty(*tyidx).bitw();
        let [lhsr, rhsr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Signed,
                    out_fill: RegCnstrFill::Signed,
                    regs: &[Reg::RAX],
                },
                RegCnstr::Input {
                    in_iidx: *rhs,
                    in_fill: RegCnstrFill::Signed,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
            ],
        )?;

        match bitw {
            64 => {
                self.asm.push_inst(IcedInst::with2(
                    Code::Cmovl_r64_rm64,
                    lhsr.to_reg64(),
                    rhsr.to_reg64(),
                ));
                self.asm.push_inst(IcedInst::with2(
                    Code::Cmp_rm64_r64,
                    lhsr.to_reg64(),
                    rhsr.to_reg64(),
                ));
            }
            x => todo!("{x}"),
        }
        Ok(())
    }

    fn i_srem(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        SRem { tyidx, lhs, rhs }: &SRem,
    ) -> Result<(), CompilationError> {
        let bitw = self.m.ty(*tyidx).bitw();
        let [_lhsr, rhsr, _] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Signed,
                    regs: &[Reg::RAX],
                    clobber: true,
                },
                RegCnstr::Input {
                    in_iidx: *rhs,
                    in_fill: RegCnstrFill::Signed,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::Output {
                    out_fill: RegCnstrFill::Signed,
                    regs: &[Reg::RDX],
                    can_be_same_as_input: false,
                },
            ],
        )?;
        assert_ne!(rhsr, Reg::RAX);
        assert_ne!(rhsr, Reg::RDX);
        assert!(bitw > 0 && bitw <= 64);
        self.asm
            .push_inst(IcedInst::with1(Code::Idiv_rm64, rhsr.to_reg64()));
        self.asm.push_inst(Ok(IcedInst::with(Code::Cqo)));
        Ok(())
    }

    fn i_store(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        inst @ Store { val, .. }: &Store,
    ) -> Result<(), CompilationError> {
        match b.inst_ty(self.m, *val) {
            Ty::Double | Ty::Float => self._i_store_float(ra, b, iidx, inst),
            Ty::Func(_) => todo!(),
            Ty::Int(_) | Ty::Ptr(_) => self.i_store_intptr(ra, b, iidx, inst),
            Ty::Void => unreachable!(),
        }
    }

    fn i_sub(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Sub {
            tyidx: _,
            lhs,
            rhs,
            nuw,
            nsw,
        }: &Sub,
    ) -> Result<(), CompilationError> {
        // We don't handle nuw or nsw yet.
        assert!(!*nuw && !*nsw);
        let bitw = b.inst_bitw(self.m, *lhs);
        assert_eq!(bitw, b.inst_bitw(self.m, *rhs));
        let in_fill = match bitw {
            32 | 64 => RegCnstrFill::Undefined,
            x => todo!("{x}"),
        };
        if let Some(0) = self.sign_ext_op_for_imm32(b, *lhs) {
            let [rhsr] = ra.alloc(
                self,
                iidx,
                [RegCnstr::InputOutput {
                    in_iidx: *rhs,
                    in_fill,
                    out_fill: RegCnstrFill::Signed,
                    regs: &NORMAL_GP_REGS,
                }],
            )?;

            self.asm
                .push_inst(IcedInst::with1(Code::Neg_rm64, rhsr.to_reg64()));
        } else if let Some(imm) = self.sign_ext_op_for_imm32(b, *rhs) {
            let [lhsr] = ra.alloc(
                self,
                iidx,
                [RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill,
                    out_fill: RegCnstrFill::Signed,
                    regs: &NORMAL_GP_REGS,
                }],
            )?;

            self.asm
                .push_inst(IcedInst::with2(Code::Sub_rm64_imm32, lhsr.to_reg64(), imm));
        } else {
            let [lhsr, rhsr] = ra.alloc(
                self,
                iidx,
                [
                    RegCnstr::InputOutput {
                        in_iidx: *lhs,
                        in_fill: in_fill.clone(),
                        out_fill: RegCnstrFill::Signed,
                        regs: &NORMAL_GP_REGS,
                    },
                    RegCnstr::Input {
                        in_iidx: *rhs,
                        in_fill,
                        regs: &NORMAL_GP_REGS,
                        clobber: false,
                    },
                ],
            )?;

            self.asm.push_inst(IcedInst::with2(
                Code::Sub_rm64_r64,
                lhsr.to_reg64(),
                rhsr.to_reg64(),
            ));
        }
        Ok(())
    }

    fn i_threadlocal(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        tl_off: u32,
    ) -> Result<(), CompilationError> {
        let [outr] = ra.alloc(
            self,
            iidx,
            [RegCnstr::Output {
                out_fill: RegCnstrFill::Zeroed,
                regs: &NORMAL_GP_REGS,
                can_be_same_as_input: false,
            }],
        )?;
        self.asm.push_inst(IcedInst::with2(
            Code::Sub_rm64_imm32,
            outr.to_reg64(),
            i32::try_from(tl_off).unwrap(),
        ));
        let mut iceinst = IcedInst::with2(
            Code::Mov_r64_rm64,
            outr.to_reg64(),
            MemoryOperand::with_base_displ(IcedReg::None, 0),
        )
        .unwrap();
        iceinst.set_segment_prefix(IcedReg::FS);
        self.asm.push_inst(Ok(iceinst));
        Ok(())
    }

    fn i_trunc(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        Trunc { val, nuw, nsw, .. }: &Trunc,
    ) -> Result<(), CompilationError> {
        // We don't handle nuw or nsw yet.
        assert!(!*nuw && !*nsw);

        let [_] = ra.alloc(
            self,
            iidx,
            [RegCnstr::Cast {
                in_iidx: *val,
                out_fill: RegCnstrFill::Undefined,
                regs: &NORMAL_GP_REGS,
            }],
        )?;
        Ok(())
    }

    fn i_udiv(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        UDiv {
            tyidx: _,
            lhs,
            rhs,
            exact,
        }: &UDiv,
    ) -> Result<(), CompilationError> {
        assert!(!*exact);

        let bitw = b.inst_bitw(self.m, *lhs);
        let [_lhsr, rhsr, _] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Zeroed,
                    out_fill: RegCnstrFill::Zeroed,
                    regs: &[Reg::RAX],
                },
                RegCnstr::Input {
                    in_iidx: *rhs,
                    in_fill: RegCnstrFill::Zeroed,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::Clobber { reg: Reg::RDX },
            ],
        )?;
        assert_ne!(rhsr, Reg::RAX);
        assert_ne!(rhsr, Reg::RDX);
        assert!(bitw > 0 && bitw <= 64);
        self.asm
            .push_inst(IcedInst::with1(Code::Div_rm64, rhsr.to_reg64()));
        self.asm.push_inst(IcedInst::with2(
            Code::Xor_rm32_r32,
            IcedReg::EDX,
            IcedReg::EDX,
        ));
        Ok(())
    }

    fn i_uitofp(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        UIToFP { tyidx, val, nneg }: &UIToFP,
    ) -> Result<(), CompilationError> {
        // We don't support `nneg` yet.
        assert!(!*nneg);
        let [srcr, tgtr, tmpr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::Input {
                    in_iidx: *val,
                    in_fill: RegCnstrFill::Zeroed,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
                RegCnstr::Output {
                    out_fill: RegCnstrFill::Undefined,
                    regs: &ALL_XMM_REGS,
                    can_be_same_as_input: false,
                },
                RegCnstr::Temp {
                    regs: &ALL_XMM_REGS,
                },
            ],
        )?;

        match self.m.ty(*tyidx) {
            Ty::Double => {
                // We generate similar code to LLVM in X86ISelLowering. Note: this is non-strict
                // floating point: it produces -0.0 instead of +0.0!
                let c0_lidx =
                    self.push_data(8, &[0, 0, 48, 67, 0, 0, 48, 69, 0, 0, 0, 0, 0, 0, 0, 0]);
                let c1_lidx =
                    self.push_data(8, &[0, 0, 0, 0, 0, 0, 48, 67, 0, 0, 0, 0, 0, 0, 48, 69]);
                self.asm.push_inst(IcedInst::with2(
                    Code::Addsd_xmm_xmmm64,
                    tgtr.to_xmm(),
                    tmpr.to_xmm(),
                ));
                self.asm.push_inst(IcedInst::with2(
                    Code::Unpckhpd_xmm_xmmm128,
                    tgtr.to_xmm(),
                    tmpr.to_xmm(),
                ));
                self.asm.push_inst(IcedInst::with2(
                    Code::Movapd_xmmm128_xmm,
                    tgtr.to_xmm(),
                    tmpr.to_xmm(),
                ));
                self.asm.push_reloc(
                    IcedInst::with2(
                        Code::Subpd_xmm_xmmm128,
                        tmpr.to_xmm(),
                        MemoryOperand::with_base_displ(IcedReg::RIP, 0),
                    ),
                    RelocKind::RipRelativeWithLabel(c1_lidx),
                );
                self.asm.push_reloc(
                    IcedInst::with2(
                        Code::Punpckldq_xmm_xmmm128,
                        tmpr.to_xmm(),
                        MemoryOperand::with_base_displ(IcedReg::RIP, 0),
                    ),
                    RelocKind::RipRelativeWithLabel(c0_lidx),
                );
                self.asm.push_inst(IcedInst::with2(
                    Code::Movq_xmm_rm64,
                    tmpr.to_xmm(),
                    srcr.to_reg64(),
                ));
            }
            Ty::Float => todo!(),
            _ => unreachable!(),
        }
        Ok(())
    }

    fn i_xor(
        &mut self,
        ra: &mut RegAlloc<Self>,
        b: &Block,
        iidx: InstIdx,
        Xor { tyidx: _, lhs, rhs }: &Xor,
    ) -> Result<(), CompilationError> {
        let bitw = b.inst_bitw(self.m, *lhs);
        assert_eq!(bitw, b.inst_bitw(self.m, *rhs));
        let out_fill = match bitw {
            32 | 64 => RegCnstrFill::Zeroed,
            _ => RegCnstrFill::Undefined,
        };
        let [lhsr, rhsr] = ra.alloc(
            self,
            iidx,
            [
                RegCnstr::InputOutput {
                    in_iidx: *lhs,
                    in_fill: RegCnstrFill::Undefined,
                    out_fill,
                    regs: &NORMAL_GP_REGS,
                },
                RegCnstr::Input {
                    in_iidx: *rhs,
                    in_fill: RegCnstrFill::Undefined,
                    regs: &NORMAL_GP_REGS,
                    clobber: false,
                },
            ],
        )?;
        self.asm.push_inst(match bitw {
            1..=32 => IcedInst::with2(Code::Xor_rm32_r32, lhsr.to_reg32(), rhsr.to_reg32()),
            x => todo!("{x}"),
        });

        Ok(())
    }

    fn i_zext(
        &mut self,
        ra: &mut RegAlloc<Self>,
        _b: &Block,
        iidx: InstIdx,
        ZExt { val, .. }: &ZExt,
    ) -> Result<(), CompilationError> {
        let [_] = ra.alloc(
            self,
            iidx,
            [RegCnstr::Cast {
                in_iidx: *val,
                out_fill: RegCnstrFill::Zeroed,
                regs: &NORMAL_GP_REGS,
            }],
        )?;
        Ok(())
    }
}

enum RegOrMemOp {
    Reg(Reg),
    MemOp(Reg, i64),
}

#[derive(Debug)]
struct IntermediateGuard {
    patch_label: LabelIdx,
    bid: aot_ir::BBlockId,
    deopt_frames: SmallVec<[DeoptFrame<Reg>; 1]>,
    extra_stack_len: u32,
    switch: Option<Switch>,
}

/// x64 tests. These use an unusual form of pattern matching. Instead of using concrete register
/// names, one can refer to a class of registers e.g. `r.8` is all 8-bit registers. To match a
/// register name but ignore its value uses `r.8._`: to match a register name use `r.8.x`.
///
/// Suffixes: must be unique (i.e. `r.8.x` and `r.8.y` must refer to different registers); and they
/// refer to the "underlying" register (e.g. `r.8.x` and `r.64.x` might match `al` and `RAX` which
/// is considered the same register, but will fail to match against `al` and `RBX`).
///
/// Note that general purpose (`r.`) and floating point (`fp.`) registers occupy different suffix
/// classes (i.e. `r.8.x` and `fp.128.x` do not match the same register "x").
#[cfg(test)]
mod test {
    use super::X64HirToAsm;
    use crate::{
        compile::j2::{
            hir::{InstIdx, Mod, ModKind},
            hir_parser::str_to_mod,
            hir_to_asm::HirToAsm,
            x64::x64regalloc::Reg,
        },
        location::{HotLocation, HotLocationKind},
        mt::MT,
    };
    use fm::{FMBuilder, FMatcher};
    use lazy_static::lazy_static;
    use parking_lot::Mutex;
    use regex::{Regex, RegexBuilder};
    use std::{
        collections::{HashMap, HashSet},
        sync::Arc,
    };

    /// All x64 registers sorted by class. Later we allow users to match all (e.g.) 8 bit registers with `r.8._`.
    const X64_REGS: [(&str, &str); 4] = [
        (
            "8",
            "al|bl|cl|dl|sil|dil|spl|bpl|r8b|r9b|r10b|r11b|r12b|r13b|r14b|r15b|ah|bh|ch|dh",
        ),
        (
            "16",
            "ax|bx|cx|dx|si|di|sp|bp|r8w|r9w|r10w|r11w|r12w|r13w|r14w|r15w",
        ),
        (
            "32",
            "eax|ebx|ecx|edx|esi|edi|esp|ebp|r8d|r9d|r10d|r11d|r12d|r13d|r14d|r15d",
        ),
        (
            "64",
            "rax|rbx|rcx|rdx|rsi|rdi|rsp|rbp|r8|r9|r10|r11|r12|r13|r14|r15",
        ),
    ];

    const X64_RAW_REGS_MAP: [[&str; 5]; 16] = [
        ["rax", "eax", "ax", "ah", "al"],
        ["rbx", "ebx", "bx", "bh", "bl"],
        ["rcx", "ecx", "cx", "ch", "cl"],
        ["rdx", "edx", "dx", "dh", "dl"],
        ["rsi", "esi", "si", "", "sil"],
        ["rdi", "edi", "di", "", "dil"],
        ["rsp", "esp", "sp", "", "spl"],
        ["rbp", "ebp", "bp", "", "bpl"],
        ["r8", "r8d", "r8w", "", "r8b"],
        ["r9", "r9d", "r9w", "", "r9b"],
        ["r10", "r10d", "r10w", "", "r10b"],
        ["r11", "r11d", "r11w", "", "r11b"],
        ["r12", "r12d", "r12w", "", "r12b"],
        ["r13", "r13d", "r13w", "", "r13b"],
        ["r14", "r14d", "r14w", "", "r14b"],
        ["r15", "r15d", "r15w", "", "r15b"],
    ];

    lazy_static! {
        static ref X64_REGS_MAP: HashMap<&'static str, usize> = {
            let mut map = HashMap::new();
            for (i, regs) in X64_RAW_REGS_MAP.iter().enumerate() {
                for r in regs.iter() {
                    if !r.is_empty() {
                        map.insert(*r, i);
                    }
                }
            }
            map
        };

        /// Use `{{name}}` to match non-literal strings in tests.
        static ref PTN_RE: Regex = {
            Regex::new(r"\{\{.+?\}\}").unwrap()
        };

        static ref PTN_RE_IGNORE: Regex = {
            Regex::new(r"\{\{_}\}").unwrap()
        };

        static ref FP_REG_IGNORE_RE: Regex = {
            Regex::new(r"fp\.128\._").unwrap()
        };

        static ref FP_REG_NAME_RE: Regex = {
            Regex::new(r"fp\.128\.[0-9a-z]+").unwrap()
        };

        static ref FP_REG_TEXT_RE: Regex = {
            Regex::new(r"xmm[0-9][0-5]?").unwrap()
        };

        static ref TEXT_RE: Regex = {
            Regex::new(r"[a-zA-Z0-9\._]+").unwrap()
        };
    }

    fn fmatcher(ptn: &str) -> FMatcher<'_> {
        let mut fmb = FMBuilder::new(ptn)
            .unwrap()
            .name_matching_validator(|names| {
                let mut gp_reg_vals = vec![None; 16];
                let mut fp_reg_vals = HashSet::new();
                let mut fp_reg_count = 0;
                let mut result = true;
                for (hl_name, reg) in names.iter() {
                    if hl_name.starts_with("r.") {
                        let hl_name = hl_name.split('.').nth(2).unwrap();
                        let reg_i = X64_REGS_MAP[reg];
                        if let Some(x) = gp_reg_vals[reg_i] {
                            if x != hl_name {
                                result = false;
                                break;
                            }
                        } else {
                            gp_reg_vals[reg_i] = Some(hl_name);
                        }
                    } else if hl_name.starts_with("fp.") {
                        fp_reg_vals.insert(reg);
                        fp_reg_count += 1;
                        if fp_reg_vals.len() != fp_reg_count {
                            result = false;
                            break;
                        }
                    }
                }
                result
            })
            .name_matcher_ignore(PTN_RE_IGNORE.clone(), TEXT_RE.clone())
            .name_matcher(PTN_RE.clone(), TEXT_RE.clone())
            .name_matcher_ignore(FP_REG_IGNORE_RE.clone(), FP_REG_TEXT_RE.clone())
            .name_matcher(FP_REG_NAME_RE.clone(), FP_REG_TEXT_RE.clone());

        for (class_name, regs) in X64_REGS {
            let class_re = RegexBuilder::new(&format!("r\\.{class_name}\\.[0-9a-z]+"))
                .case_insensitive(true)
                .build()
                .unwrap();
            let class_ignore_re = RegexBuilder::new(&format!("r\\.{class_name}\\._"))
                .case_insensitive(true)
                .build()
                .unwrap();
            let regs_re = RegexBuilder::new(regs)
                .case_insensitive(true)
                .build()
                .unwrap();
            fmb = fmb
                .name_matcher_ignore(class_ignore_re, regs_re.clone())
                .name_matcher(class_re, regs_re);
        }

        fmb.build().unwrap()
    }

    #[test]
    fn check_matching() {
        let fmm = fmatcher("r.8.x r.8.y r.64.x");
        assert!(fmm.matches("al bl rax").is_ok());
        assert!(fmm.matches("al al rax").is_err());
        assert!(fmm.matches("al bl rbx").is_err());
        assert!(fmm.matches("al bl eax").is_err());

        let fmm = fmatcher("r.8.x r.8._ r.64.x");
        assert!(fmm.matches("al bl rax").is_ok());
        assert!(fmm.matches("al al rax").is_ok());

        let fmm = fmatcher("fp.128.x fp.128.y fp.128.x");
        assert!(fmm.matches("xmm0 xmm1 xmm0").is_ok());
        assert!(fmm.matches("xmm0 xmm0 xmm0").is_err());

        let fmm = fmatcher("fp.128.x fp.128.y fp.128._");
        assert!(fmm.matches("xmm0 xmm1 xmm0").is_ok());
        assert!(fmm.matches("xmm0 xmm0 xmm0").is_err());
        assert!(fmm.matches("xmm0 xmm1 xmm2").is_ok());
        assert!(fmm.matches("xmm0 xmm1 xmm0").is_ok());
    }

    /// For the module `mod_s`, run it through the x64 backend and check the output matches one of
    /// the fm patterns in `ptns`.
    fn codegen_and_test(mod_s: &str, ptns: &[&str]) {
        let m = str_to_mod::<Reg>(mod_s);
        let mt = MT::new().unwrap();
        let hl = Arc::new(Mutex::new(HotLocation {
            kind: HotLocationKind::Tracing(mt.next_trace_id()),
            tracecompilation_errors: 0,
            #[cfg(feature = "ykd")]
            debug_str: None,
        }));
        let be = X64HirToAsm::new(&m);
        let log = HirToAsm::new(&m, hl, be).build_test().unwrap();

        let mut failures = Vec::new();
        for ptn in ptns {
            match fmatcher(ptn).matches(&log) {
                Ok(()) => return,
                Err(e) => failures.push(format!("{e:?}\n\n{log}\n\n{ptn}")),
            }
        }
        panic!("{}", failures.join("\n\n"));
    }

    #[test]
    fn imm8s() {
        let m = str_to_mod(
            "
          %0: i8 = 0
          %1: i8 = 0xFF
          %2: i16 = 0
          %3: i16 = 0xFF
          %4: i16 = 0x100
          %5: i16 = 0xFFFF
        ",
        );

        let Mod {
            kind: ModKind::Test { block: b, .. },
            ..
        } = &m
        else {
            panic!()
        };
        let be = X64HirToAsm::new(&m);

        assert_eq!(be.zero_ext_op_for_imm8(b, InstIdx::from(0)), Some(0));
        assert_eq!(be.zero_ext_op_for_imm8(b, InstIdx::from(1)), Some(0xFF));
        assert_eq!(be.zero_ext_op_for_imm8(b, InstIdx::from(2)), Some(0));
        assert_eq!(be.zero_ext_op_for_imm8(b, InstIdx::from(3)), Some(0xFF));
        assert_eq!(be.zero_ext_op_for_imm8(b, InstIdx::from(4)), None);
        assert_eq!(be.zero_ext_op_for_imm8(b, InstIdx::from(5)), None);
    }

    #[test]
    fn imm32s() {
        let m = str_to_mod(
            "
          %0: i1 = 0
          %1: i1 = 0x1
          %2: i8 = 0
          %3: i8 = 0xFF
          %4: i16 = 0
          %5: i16 = 0xFFFF
          %6: i32 = 0
          %7: i32 = 0xFFFFFFFF
          %8: i64 = 0
          %9: i64 = 0xFFFFFFFF
          %10: i64 = 0x100000000
          %11: i64 = 0xFFFFFFFFFFFFFFFF
          %12: i64 = 0xFFFFFFFFFFFFFFFE
        ",
        );

        let Mod {
            kind: ModKind::Test { block: b, .. },
            ..
        } = &m
        else {
            panic!()
        };
        let be = X64HirToAsm::new(&m);

        assert_eq!(be.sign_ext_op_for_imm32(b, InstIdx::from(6)), Some(0));
        assert_eq!(be.sign_ext_op_for_imm32(b, InstIdx::from(7)), Some(-1));
        assert_eq!(be.sign_ext_op_for_imm32(b, InstIdx::from(8)), Some(0));
        assert_eq!(be.sign_ext_op_for_imm32(b, InstIdx::from(9)), None);
        assert_eq!(be.sign_ext_op_for_imm32(b, InstIdx::from(10)), None);
        assert_eq!(be.sign_ext_op_for_imm32(b, InstIdx::from(11)), Some(-1));
        assert_eq!(be.sign_ext_op_for_imm32(b, InstIdx::from(12)), Some(-2));

        assert_eq!(be.zero_ext_op_for_imm32(b, 1, InstIdx::from(0)), Some(0));
        assert_eq!(be.zero_ext_op_for_imm32(b, 1, InstIdx::from(1)), Some(1));
        assert_eq!(be.zero_ext_op_for_imm32(b, 8, InstIdx::from(2)), Some(0));
        assert_eq!(be.zero_ext_op_for_imm32(b, 8, InstIdx::from(3)), Some(255));
        assert_eq!(be.zero_ext_op_for_imm32(b, 16, InstIdx::from(4)), Some(0));
        assert_eq!(
            be.zero_ext_op_for_imm32(b, 16, InstIdx::from(5)),
            Some(65535)
        );
        assert_eq!(be.zero_ext_op_for_imm32(b, 32, InstIdx::from(6)), Some(0));
        assert_eq!(be.zero_ext_op_for_imm32(b, 32, InstIdx::from(7)), Some(-1));

        assert_eq!(be.zero_ext_op_for_imm32(b, 64, InstIdx::from(8)), Some(0));
        assert_eq!(be.zero_ext_op_for_imm32(b, 64, InstIdx::from(9)), None);
        assert_eq!(be.zero_ext_op_for_imm32(b, 64, InstIdx::from(10)), None);
        assert_eq!(be.zero_ext_op_for_imm32(b, 64, InstIdx::from(11)), None);
        assert_eq!(be.zero_ext_op_for_imm32(b, 64, InstIdx::from(12)), None);
    }

    #[test]
    fn load_to_mem_op() {
        let m = str_to_mod(
            "
          extern abort()

          %0: ptr = arg [reg]
          %1: i8 = load %0
          %2: i8 = 10
          %3: i8 = add %1, %2
          %4: i8 = load %0
          %5: i8 = add %1, %2
          %6: i8 = add %4, %2
          store %6, %0
          %8: i8 = add %4, %2
          %9: i8 = load %0
          %10: i8 = add %9, %2
          %11: ptr = @abort
          call abort %11()
          %13: i8 = load %0
          %14: i8 = add %13, %2
        ",
        );

        let Mod {
            kind: ModKind::Test { block: b, .. },
            ..
        } = &m
        else {
            panic!()
        };
        let be = X64HirToAsm::new(&m);

        assert_eq!(
            be.try_load_to_mem_op(b, InstIdx::from(3), InstIdx::from(1)),
            Some((InstIdx::from(0), 0))
        );
        assert_eq!(
            be.try_load_to_mem_op(b, InstIdx::from(5), InstIdx::from(1)),
            None
        );
        assert_eq!(
            be.try_load_to_mem_op(b, InstIdx::from(6), InstIdx::from(4)),
            Some((InstIdx::from(0), 0))
        );
        assert_eq!(
            be.try_load_to_mem_op(b, InstIdx::from(8), InstIdx::from(4)),
            None
        );
        assert_eq!(
            be.try_load_to_mem_op(b, InstIdx::from(10), InstIdx::from(4)),
            None
        );
        assert_eq!(
            be.try_load_to_mem_op(b, InstIdx::from(10), InstIdx::from(9)),
            Some((InstIdx::from(0), 0))
        );
        assert_eq!(
            be.try_load_to_mem_op(b, InstIdx::from(14), InstIdx::from(9)),
            None
        );
        assert_eq!(
            be.try_load_to_mem_op(b, InstIdx::from(14), InstIdx::from(13)),
            Some((InstIdx::from(0), 0))
        );
    }

    #[test]
    fn stackoff() {
        codegen_and_test(
            "
              %0: ptr = arg [stackoff 32]
              %1: i8 = load %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %0: ptr = arg [StackOff(32)]
              lea r.64.x, [rbp-0x20]
              ; %1: i8 = load %0
              movzx r.32._, byte [r.64.x]
              ...
            "],
        );
    }

    // Individual instructions.

    #[test]
    fn cg_abs() {
        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = abs %0
              exit [%1]
            ",
            &["
              ...
              ; %1: i64 = abs %0, false
              mov r.64.x, r.64.y
              neg r.64.y
              cmovl r.64.y, r.64.x
              ...
            "],
        );
    }

    #[test]
    fn cg_add() {
        // i8
        codegen_and_test(
            "
              %0: i8 = arg [reg]
              %1: i8 = arg [reg]
              %2: i8 = add %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i8 = add %0, %1
              add r.32.x, r.32.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i8 = arg [reg]
              %1: i8 = 32
              %2: i8 = add %0, %1
              exit [%2]
            ",
            &["
              ...
              ; %2: i8 = add %0, %1
              add r.32.x, 0x20
              ...
            "],
        );

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: i32 = add %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i32 = add %0, %1
              add r.32.x, r.32.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 32
              %2: i32 = add %0, %1
              exit [%2]
            ",
            &["
              ...
              ; %2: i32 = add %0, %1
              add r.32.x, 0x20
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 0xFFFFFFFF
              %2: i32 = add %0, %1
              exit [%2]
            ",
            &["
              ...
              ; %2: i32 = add %0, %1
              add r.32.x, 0xFFFFFFFF
              ...
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = arg [reg]
              %2: i64 = add %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i64 = add %0, %1
              add r.64.x, r.64.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 32
              %2: i64 = add %0, %1
              exit [%2]
            ",
            &["
              ...
              ; %2: i64 = add %0, %1
              add r.64.x, 0x20
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 0xFFFFFFFF
              %2: i64 = add %0, %1
              exit [%2]
            ",
            &["
              ...
              mov r.32.y, 0xFFFFFFFF
              ; %2: i64 = add %0, %1
              add r.64.x, r.64.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 0xFFFFFFFFAB
              %2: i64 = add %0, %1
              exit [%2]
            ",
            &["
              ...
              mov r.64.x, 0xFFFFFFFFAB
              ; %2: i64 = add %0, %1
              add r.64._, r.64.x
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 0xFFFFFFFFFFFFFFFF
              %2: i64 = add %0, %1
              exit [%2]
            ",
            &["
              ...
              ; %2: i64 = add %0, %1
              add r.64._, 0xFFFFFFFFFFFFFFFF
              ...
            "],
        );
    }

    #[test]
    fn cg_and() {
        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 0xFFFFFFFF
              %2: i32 = and %0, %1
              exit [%2]
            ",
            &["
              ...
              ; %2: i32 = and %0, %1
              and r.32._, 0xFFFFFFFF
              ...
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 0x0FFFFFFF
              %2: i64 = and %0, %1
              exit [%2]
            ",
            &["
              ...
              ; %2: i64 = and %0, %1
              and r.64._, 0xFFFFFFF
              ...
            "],
        );
    }

    #[test]
    fn cg_ashr() {
        // Constant RHS

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 3
              %2: i32 = ashr %0, %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %2: i32 = ashr %0, %1
              sar r.64._, 3
              ...
            "],
        );

        // Variable RHS

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: i32 = ashr %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i32 = ashr %0, %1
              sar r.64.x, cl
              ...
            "],
        );
    }

    #[test]
    fn cg_call() {
        codegen_and_test(
            "
              extern abort()

              %0: ptr = @abort
              call abort %0()
              exit []
            ",
            &[
                "
              ...
              ; %0: ptr = {{addr}}
              ; call %0()
              call {{addr}}
              ...
            ",
                "
              ...
              ; %0: ptr = {{addr}}
              mov r.64.x, {{addr}}
              ; call %0()
              call r.64.x
              ...
            ",
            ],
        );

        codegen_and_test(
            "
              extern abort()

              %0: ptr = arg [reg]
              call abort %0()
              exit [%0]
            ",
            &["
              ...
              mov rax, r.64._
              ; call %0()
              call rax
              ...
            "],
        );

        codegen_and_test(
            "
              extern puts(ptr) -> i32

              %0: ptr = arg [reg]
              %1: ptr = @puts
              %2: i32 = call puts %1(%0)
              %3: i32 = 1
              %4: i32 = add %2, %3
              blackbox %4
              exit [%0]
            ",
            &[
                r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              mov rdi, r.64.x
              ; %1: ptr = {{addr}}
              ; %2: i32 = call %1(%0)
              call {{addr}}
              ...
              ; %4: i32 = add %2, %3
              add r.32._, 1
              ; blackbox %4
              ; exit [%0]
            "#,
                r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              mov rdi, r.64.x
              ; %1: ptr = {{addr}}
              mov rax, {{addr}}
              ; %2: i32 = call %1(%0)
              call rax
              ...
              ; %4: i32 = add %2, %3
              add r.32._, 1
              ; blackbox %4
              ; exit [%0]
            "#,
            ],
        );

        codegen_and_test(
            "
              extern puts(ptr) -> i32

              %0: ptr = arg [reg]
              %1: ptr = arg [reg]
              %2: i32 = call puts %1(%0)
              %3: i32 = 1
              %4: i32 = add %2, %3
              blackbox %4
              exit [%0, %1]
            ",
            &["
              ...
              ; %2: i32 = call %1(%0)
              call rax
              ...
              ; %4: i32 = add %2, %3
              add r.32._, 1
              ...
            "],
        );

        codegen_and_test(
            "
              extern printf(ptr, ...) -> i32

              %0: ptr = arg [reg]
              %1: ptr = @printf
              %2: i64 = 2
              %3: i32 = call printf %1(%0, %2)
              %4: i32 = 1
              %5: i32 = add %3, %4
              blackbox %5
              exit [%0]
            ",
            &["
              ...
              ; %3: i32 = call %1(%0, %2)
              mov eax, 0
              call {{addr}}
              ...
              ; %5: i32 = add %3, %4
              add r.32._, 1
              ...
            "],
        );

        codegen_and_test(
            "
              extern printf(ptr, ...) -> i32

              %0: ptr = arg [reg]
              %1: ptr = arg [reg]
              %2: i64 = 2
              %3: i32 = call printf %1(%0, %2)
              %4: i32 = 1
              %5: i32 = add %3, %4
              blackbox %5
              exit [%0, %1]
            ",
            &["
              ...
              ; %3: i32 = call %1(%0, %2)
              mov eax, 0
              call r.64._
              ...
              ; %5: i32 = add %3, %4
              add r.32._, 1
              ...
            "],
        );

        codegen_and_test(
            r#"
              extern f(float, double)

              %0: ptr = arg [reg "rax"]
              %1: float = arg [reg "xmm15"]
              %2: double = arg [reg "xmm14"]
              call f %0(%1, %2)
              exit [%0, %1, %2]
            "#,
            &[r#"
              ...
              ; %0: ptr = arg [Reg("rax")]
              ; %1: float = arg [Reg("xmm15")]
              ; %2: double = arg [Reg("xmm14")]
              ...
              movsd xmm0, xmm15
              movsd xmm1, xmm14
              ; call %0(%1, %2)
              call rax
              ...
            "#],
        );

        codegen_and_test(
            r#"
              extern f() -> double

              %0: double = arg [reg "xmm15"]
              %1: ptr = arg [reg "r15"]
              %2: double = call f %1()
              %3: double = fadd %0, %2
              exit [%3, %1]
            "#,
            &[r#"
              ...
              mov rax, r15
              ; %2: double = call %1()
              call rax
              movsd xmm15, [rbp-{{_}}]
              ; %3: double = fadd %0, %2
              addsd xmm15, xmm0
              ; exit [%3, %1]
            "#],
        );

        codegen_and_test(
            r#"
              extern f(double) -> double

              %0: double = arg [reg "xmm15"]
              %1: ptr = arg [reg "r15"]
              %2: double = call f %1(%0)
              %3: double = fadd %0, %2
              exit [%3, %1]
            "#,
            &[r#"
              ...
              mov rax, r15
              movsd xmm0, xmm15
              ; %2: double = call %1(%0)
              call rax
              movsd xmm15, [rbp-{{_}}]
              ; %3: double = fadd %0, %2
              addsd xmm15, xmm0
              ; exit [%3, %1]
            "#],
        );

        codegen_and_test(
            r#"
              extern f(float, double, ...)

              %0: ptr = arg [reg "rax"]
              %1: float = arg [reg "xmm15"]
              %2: double = arg [reg "xmm14"]
              call f %0(%1, %2)
              exit [%0, %1, %2]
            "#,
            &[r#"
              ...
              ; %0: ptr = arg [Reg("rax")]
              ; %1: float = arg [Reg("xmm15")]
              ; %2: double = arg [Reg("xmm14")]
              ...
              mov r.64.x, rax
              movsd xmm0, xmm15
              movsd xmm1, xmm14
              ; call %0(%1, %2)
              mov eax, 2
              call r.64.x
              ...
            "#],
        );

        codegen_and_test(
            r#"
              extern f(...) -> double

              %0: double = arg [reg "xmm15"]
              %1: ptr = arg [reg "r15"]
              %2: double = call f %1()
              %3: double = fadd %0, %2
              exit [%3, %1]
            "#,
            &[r#"
              ...
              ; %2: double = call %1()
              mov eax, 0
              call r.64._
              movsd xmm15, [rbp-{{_}}]
              ; %3: double = fadd %0, %2
              addsd xmm15, xmm0
              ; exit [%3, %1]
            "#],
        );

        codegen_and_test(
            r#"
              extern f(double, ...) -> double

              %0: double = arg [reg "xmm15"]
              %1: ptr = arg [reg "r15"]
              %2: double = call f %1(%0)
              %3: double = fadd %0, %2
              exit [%3, %1]
            "#,
            &[r#"
              ...
              movsd xmm0, xmm15
              ; %2: double = call %1(%0)
              mov eax, 1
              call r.64._
              movsd xmm15, [rbp-{{_}}]
              ; %3: double = fadd %0, %2
              addsd xmm15, xmm0
              ; exit [%3, %1]
            "#],
        );
    }

    #[test]
    fn cg_const() {
        // Integers

        // i8
        codegen_and_test(
            "
              %0: i8 = 0xFF
              %1: i8 = 0xAB
              %2: i8 = add %0, %1
              %3: i8 = add %1, %0
              blackbox %2
              blackbox %3
              exit []
            ",
            &["
              ...
              ; %0: i8 = 255
              mov r.32.x, 0xFF
              ; %1: i8 = 171
              mov r.32.y, 0xAB
              ; %2: i8 = add %0, %1
              add r.32.x, 0xFFFFFFAB
              ; %3: i8 = add %1, %0
              add r.32.y, 0xFFFFFFFF
              ...
            "],
        );

        // i32
        codegen_and_test(
            "
              %0: i32 = 0xFFFFFFFF
              %1: i32 = 0xABCD1234
              %2: i32 = add %0, %1
              blackbox %2
              exit []
            ",
            &["
              ...
              ; %0: i32 = 4294967295
              mov r.32.x, 0xFFFFFFFF
              ; %1: i32 = 2882343476
              ; %2: i32 = add %0, %1
              add r.32.x, 0xABCD1234
              ; blackbox %2
              ; exit []
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: i64 = 0xFFFFFFFF
              %1: i64 = 0xABCD1234
              %2: i64 = add %0, %1
              blackbox %2
              exit []
            ",
            &["
              ...
              ; %0: i64 = 4294967295
              mov r.32.x, 0xFFFFFFFF
              ; %1: i64 = 2882343476
              mov r.32.y, 0xABCD1234
              ; %2: i64 = add %0, %1
              add r.64.x, r.64.y
              ; blackbox %2
              ; exit []
            "],
        );

        codegen_and_test(
            "
              %0: i64 = 0xFFFFFFFFFFFFFFFF
              %1: i64 = 0xFFFFFFFFFFFFFFFE
              %2: i64 = add %0, %1
              blackbox %2
              exit []
            ",
            &["
              ...
              ; %0: i64 = 18446744073709551615
              mov r.64.x, 0xFFFFFFFFFFFFFFFF
              ; %1: i64 = 18446744073709551614
              ; %2: i64 = add %0, %1
              add r.64.x, 0xFFFFFFFFFFFFFFFE
              ; blackbox %2
              ; exit []
            "],
        );

        // Doubles
        codegen_and_test(
            "
              %0: double = 1.1double
              %1: double = 2.1double
              %2: double = fadd %0, %1
              blackbox %2
              exit []
            ",
            &["
              ...
              ; %0: double = 1.1
              mov r.64.x, 0x3FF199999999999A
              movq fp.128.x, r.64.x
              ; %1: double = 2.1
              mov r.64._, 0x4000CCCCCCCCCCCD
              movq fp.128.y, r.64._
              ; %2: double = fadd %0, %1
              addsd fp.128.x, fp.128.y
              ; blackbox %2
              ; exit []
            "],
        );

        // Floats
        codegen_and_test(
            "
              %0: float = 1.1float
              %1: float = 2.1float
              %2: float = fadd %0, %1
              blackbox %2
              exit []
            ",
            &["
              ...
              ; %0: float = 1.1
              mov r.32.x, 0x3F8CCCCD
              movd fp.128.x, r.32.x
              ; %1: float = 2.1
              mov r.32._, 0x40066666
              movd fp.128.y, r.32._
              ; %2: float = fadd %0, %1
              addss fp.128.x, fp.128.y
              ; blackbox %2
              ; exit []
            "],
        );
    }

    #[test]
    fn cg_ctpop() {
        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = ctpop %0
              exit [%1]
            ",
            &["
              ...
              ; %1: i32 = ctpop %0
              popcnt r.32._, r.32.x
              ; exit [%1]
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = ctpop %0
              exit [%1]
            ",
            &["
              ...
              ; %1: i64 = ctpop %0
              popcnt r.64._, r.64.x
              ; exit [%1]
            "],
        );
    }

    #[test]
    fn cg_dynptradd() {
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i64 = arg [reg]
              %2: ptr = dynptradd %0, %1, 1
              %3: ptr = dynptradd %0, %1, 2
              %4: ptr = dynptradd %0, %1, 4
              %5: ptr = dynptradd %0, %1, 8
              %6: ptr = dynptradd %0, %1, 16
              blackbox %2
              blackbox %3
              blackbox %4
              blackbox %5
              blackbox %6
              exit [%0, %1]
            ",
            &["
              ...
              ; %2: ptr = dynptradd %0, %1, 1
              lea r.64._, [r.64.x+r.64.y]
              ; %3: ptr = dynptradd %0, %1, 2
              lea r.64._, [r.64.x+r.64.y*2]
              ; %4: ptr = dynptradd %0, %1, 4
              lea r.64._, [r.64.x+r.64.y*4]
              ; %5: ptr = dynptradd %0, %1, 8
              lea r.64._, [r.64.x+r.64.y*8]
              ; %6: ptr = dynptradd %0, %1, 16
              shl r.64.y, 4
              add r.64.y, r.64.x
              ...
            "],
        );
    }

    #[test]
    fn cg_fadd() {
        codegen_and_test(
            "
              %0: float = arg [reg]
              %1: float = arg [reg]
              %2: float = fadd %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: float = fadd %0, %1
              addss fp.128.x, fp.128.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: double = arg [reg]
              %1: double = arg [reg]
              %2: double = fadd %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: double = fadd %0, %1
              addsd fp.128.x, fp.128.y
              ...
            "],
        );
    }

    #[test]
    fn cg_fcmp() {
        // double

        codegen_and_test(
            "
               %0: double = arg [reg]
               %1: double = arg [reg]
               %2: i1 = fcmp oeq %0, %1
               %3: i1 = fcmp ogt %0, %1
               %4: i1 = fcmp oge %0, %1
               %5: i1 = fcmp olt %0, %1
               %6: i1 = fcmp ole %0, %1
               %7: i1 = fcmp one %0, %1
               %8: i1 = fcmp ueq %0, %1
               %9: i1 = fcmp ugt %0, %1
               %10: i1 = fcmp uge %0, %1
               %11: i1 = fcmp ult %0, %1
               %12: i1 = fcmp ule %0, %1
               %13: i1 = fcmp une %0, %1
               blackbox %2
               blackbox %3
               blackbox %4
               blackbox %5
               blackbox %6
               blackbox %7
               blackbox %8
               blackbox %9
               blackbox %10
               blackbox %11
               blackbox %12
               blackbox %13
               exit [%0, %1]
            ",
            &["
               ...
               ; %2: i1 = fcmp oeq %0, %1
               ucomisd fp.128.x, fp.128.y
               sete r.8.i
               setnp r.8.j
               and r.8.j, r.8.i
               ; %3: i1 = fcmp ogt %0, %1
               ucomisd fp.128.x, fp.128.y
               seta r.8._
               ; %4: i1 = fcmp oge %0, %1
               ucomisd fp.128.x, fp.128.y
               setae r.8._
               ; %5: i1 = fcmp olt %0, %1
               ucomisd fp.128.y, fp.128.x
               seta r.8._
               ; %6: i1 = fcmp ole %0, %1
               ucomisd fp.128.y, fp.128.x
               setae r.8._
               ; %7: i1 = fcmp one %0, %1
               ucomisd fp.128.x, fp.128.y
               setne r.8._
               ; %8: i1 = fcmp ueq %0, %1
               ucomisd fp.128.x, fp.128.y
               sete r.8._
               ; %9: i1 = fcmp ugt %0, %1
               ucomisd fp.128.y, fp.128.x
               setb r.8._
               ; %10: i1 = fcmp uge %0, %1
               ucomisd fp.128.y, fp.128.x
               setbe r.8._
               ; %11: i1 = fcmp ult %0, %1
               ucomisd fp.128.x, fp.128.y
               setb r.8._
               ; %12: i1 = fcmp ule %0, %1
               ucomisd fp.128.x, fp.128.y
               setbe r.8._
               ; %13: i1 = fcmp une %0, %1
               ucomisd fp.128.x, fp.128.y
               setne r.8._
               setp r.8._
               or r.8._, r.8._
               ; blackbox %2
               ...
            "],
        );

        // float

        codegen_and_test(
            "
               %0: float = arg [reg]
               %1: float = arg [reg]
               %2: i1 = fcmp oeq %0, %1
               %3: i1 = fcmp ogt %0, %1
               %4: i1 = fcmp oge %0, %1
               %5: i1 = fcmp olt %0, %1
               %6: i1 = fcmp ole %0, %1
               %7: i1 = fcmp one %0, %1
               %8: i1 = fcmp ueq %0, %1
               %9: i1 = fcmp ugt %0, %1
               %10: i1 = fcmp uge %0, %1
               %11: i1 = fcmp ult %0, %1
               %12: i1 = fcmp ule %0, %1
               %13: i1 = fcmp une %0, %1
               blackbox %2
               blackbox %3
               blackbox %4
               blackbox %5
               blackbox %6
               blackbox %7
               blackbox %8
               blackbox %9
               blackbox %10
               blackbox %11
               blackbox %12
               blackbox %13
               exit [%0, %1]
            ",
            &["
               ...
               ; %2: i1 = fcmp oeq %0, %1
               ucomiss fp.128.x, fp.128.y
               sete r.8.i
               setnp r.8.j
               and r.8.j, r.8.i
               ; %3: i1 = fcmp ogt %0, %1
               ucomiss fp.128.x, fp.128.y
               seta r.8._
               ; %4: i1 = fcmp oge %0, %1
               ucomiss fp.128.x, fp.128.y
               setae r.8._
               ; %5: i1 = fcmp olt %0, %1
               ucomiss fp.128.y, fp.128.x
               seta r.8._
               ; %6: i1 = fcmp ole %0, %1
               ucomiss fp.128.y, fp.128.x
               setae r.8._
               ; %7: i1 = fcmp one %0, %1
               ucomiss fp.128.x, fp.128.y
               setne r.8._
               ; %8: i1 = fcmp ueq %0, %1
               ucomiss fp.128.x, fp.128.y
               sete r.8._
               ; %9: i1 = fcmp ugt %0, %1
               ucomiss fp.128.y, fp.128.x
               setb r.8._
               ; %10: i1 = fcmp uge %0, %1
               ucomiss fp.128.y, fp.128.x
               setbe r.8._
               ; %11: i1 = fcmp ult %0, %1
               ucomiss fp.128.x, fp.128.y
               setb r.8._
               ; %12: i1 = fcmp ule %0, %1
               ucomiss fp.128.x, fp.128.y
               setbe r.8._
               ; %13: i1 = fcmp une %0, %1
               ucomiss fp.128.x, fp.128.y
               setne r.8._
               setp r.8._
               or r.8._, r.8._
               ; blackbox %2
               ...
            "],
        );
    }

    #[test]
    fn cg_fdiv() {
        codegen_and_test(
            "
              %0: float = arg [reg]
              %1: float = arg [reg]
              %2: float = fdiv %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: float = fdiv %0, %1
              divss fp.128.x, fp.128.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: double = arg [reg]
              %1: double = arg [reg]
              %2: double = fdiv %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: double = fdiv %0, %1
              divsd fp.128.x, fp.128.y
              ...
            "],
        );
    }

    #[test]
    fn cg_fmul() {
        codegen_and_test(
            "
              %0: float = arg [reg]
              %1: float = arg [reg]
              %2: float = fmul %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: float = fmul %0, %1
              mulss fp.128.x, fp.128.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: double = arg [reg]
              %1: double = arg [reg]
              %2: double = fmul %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: double = fmul %0, %1
              mulsd fp.128.x, fp.128.y
              ...
            "],
        );
    }

    #[test]
    fn cg_fsub() {
        codegen_and_test(
            "
              %0: float = arg [reg]
              %1: float = arg [reg]
              %2: float = fsub %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: float = fsub %0, %1
              subss fp.128.x, fp.128.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: double = arg [reg]
              %1: double = arg [reg]
              %2: double = fsub %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: double = fsub %0, %1
              subsd fp.128.x, fp.128.y
              ...
            "],
        );
    }

    #[test]
    fn cg_fpext() {
        codegen_and_test(
            "
              %0: float = arg [reg]
              %1: double = fpext %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %1: double = fpext %0
              cvtss2sd fp.128._, fp.128._
              ; blackbox %1
              ; exit [%0]
            "],
        );
    }

    #[test]
    fn cg_fptosi() {
        codegen_and_test(
            "
              %0: double = arg [reg]
              %1: float = arg [reg]
              %2: i32 = fptosi %0
              blackbox %2
              %4: i64 = fptosi %0
              blackbox %4
              %6: i32 = fptosi %1
              blackbox %6
              exit [%0, %1]
            ",
            &[r#"
              ...
              ; %0: double = arg [Reg("fp.128.x")]
              ; %1: float = arg [Reg("fp.128.y")]
              ; %2: i32 = fptosi %0
              cvttsd2si r.32._, fp.128.x
              ; blackbox %2
              ; %4: i64 = fptosi %0
              cvttsd2si r.64._, fp.128.x
              ; blackbox %4
              ; %6: i32 = fptosi %1
              cvttss2si r.32._, fp.128.y
              ; blackbox %6
              ; exit [%0, %1]
            "#],
        );
    }

    #[test]
    fn cg_guard() {
        // The standard cases
        codegen_and_test(
            "
              %0: i1 = arg [reg]
              guard true, %0, []
              exit [%0]
            ",
            &["
              ...
              ; guard true, %0, []
              bt r.32._, 0
              jae l0
              ; exit [%0]
              ; l0
              sub rsp, 0
              ; l1
              jmp l2
              ; l2
              mov rdi, rbp
              mov rsi, 0
              mov edx, 0
              mov rax, {{_}}
              call rax
            "],
        );

        codegen_and_test(
            "
              %0: i1 = arg [reg]
              guard false, %0, []
              exit [%0]
            ",
            &["
              ...
              ; guard false, %0, []
              bt r.32._, 0
              jb l0
              ; exit [%0]
              ; l0
              sub rsp, 0
              ; l1
              jmp l2
              ; l2
              mov rdi, rbp
              mov rsi, 0
              mov edx, 0
              mov rax, {{_}}
              call rax
            "],
        );

        // ICmp optimisation
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: i1 = icmp eq %0, %1
              guard true, %2, []
              exit [%0, %1]
            ",
            &["
              ...
              ; %2: i1 = icmp eq %0, %1
              ; guard true, %2, []
              cmp r.32.x, r.32.y
              jne l0
              ; exit [%0, %1]
              ...
            "],
        );

        // Icmp-const optimisation
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 0x14
              %2: i1 = icmp eq %0, %1
              guard true, %2, []
              exit [%0]
            ",
            &["
              ...
              ; %2: i1 = icmp eq %0, %1
              ; guard true, %2, []
              cmp r.32.x, 0x14
              jne l0
              ; exit [%0]
              ...
            "],
        );

        // ICmp optimisation and zero/sign fill
        codegen_and_test(
            "
              %0: i8 = arg [reg]
              %1: i8 = arg [reg]
              %2: i1 = icmp eq %0, %1
              guard true, %2, []
              exit [%0, %1]
            ",
            &[r#"
              ...
              ; %0: i8 = arg [Reg("r.64.x")]
              ; %1: i8 = arg [Reg("r.64.y")]
              and r.32.x, 0xFF
              and r.32.y, 0xFF
              ; %2: i1 = icmp eq %0, %1
              ; guard true, %2, []
              cmp r.32.x, r.32.y
              jne l0
              ; exit [%0, %1]
              ...
            "#],
        );

        codegen_and_test(
            "
              %0: i8 = arg [reg]
              %1: i8 = arg [reg]
              %2: i1 = icmp sgt %0, %1
              guard true, %2, []
              exit [%0, %1]
            ",
            &[r#"
              ...
              ; %0: i8 = arg [Reg("r.64.x")]
              ; %1: i8 = arg [Reg("r.64.y")]
              movsx r.64.x, r.8.x
              movsx r.64.y, r.8.y
              ; %2: i1 = icmp sgt %0, %1
              ; guard true, %2, []
              cmp r.32.x, r.32.y
              jle l0
              ; exit [%0, %1]
              ...
            "#],
        );

        codegen_and_test(
            "
              %0: i8 = arg [reg]
              %1: i8 = arg [reg]
              %2: i1 = icmp ugt %0, %1
              guard true, %2, []
              exit [%0, %1]
            ",
            &[r#"
              ...
              ; %0: i8 = arg [Reg("r.64.x")]
              ; %1: i8 = arg [Reg("r.64.y")]
              and r.32.x, 0xFF
              and r.32.y, 0xFF
              ; %2: i1 = icmp ugt %0, %1
              ; guard true, %2, []
              cmp r.32.x, r.32.y
              jbe l0
              ; exit [%0, %1]
              ...
            "#],
        );

        // ICmp optimisation with loads

        // i32
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i32 = arg [reg]
              %2: i32 = load %0
              %3: i1 = icmp ugt %2, %1
              guard true, %3, []
              exit [%0, %1]
            ",
            &[r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              ; %1: i32 = arg [Reg("r.64.y")]
              ; %2: i32 = load %0
              ; %3: i1 = icmp ugt %2, %1
              ; guard true, %3, []
              cmp [r.32.x], r.32.y
              jbe l0
              ; exit [%0, %1]
              ...
            "#],
        );

        // i64
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i64 = arg [reg]
              %2: i64 = load %0
              %3: i1 = icmp ugt %2, %1
              guard true, %3, []
              exit [%0, %1]
            ",
            &[r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              ; %1: i64 = arg [Reg("r.64.y")]
              ; %2: i64 = load %0
              ; %3: i1 = icmp ugt %2, %1
              ; guard true, %3, []
              cmp [r.64.x], r.64.y
              jbe l0
              ; exit [%0, %1]
              ...
            "#],
        );

        // ICmp optimisation with loads and constants

        // i8
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i8 = load %0
              %2: i8 = 7
              %3: i1 = icmp ugt %1, %2
              guard true, %3, []
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              ; %1: i8 = load %0
              ; %2: i8 = 7
              ; %3: i1 = icmp ugt %1, %2
              ; guard true, %3, []
              cmp byte [r.64.x], 7
              jbe l0
              ; exit [%0]
              ...
            "#],
        );

        // i16
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i16 = load %0
              %2: i16 = 7
              %3: i1 = icmp ugt %1, %2
              guard true, %3, []
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              ; %1: i16 = load %0
              ; %2: i16 = 7
              ; %3: i1 = icmp ugt %1, %2
              ; guard true, %3, []
              cmp word [r.64.x], 7
              jbe l0
              ; exit [%0]
              ...
            "#],
        );

        // i32
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i32 = load %0
              %2: i32 = 7
              %3: i1 = icmp ugt %1, %2
              guard true, %3, []
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              ; %1: i32 = load %0
              ; %2: i32 = 7
              ; %3: i1 = icmp ugt %1, %2
              ; guard true, %3, []
              cmp dword [r.64.x], 7
              jbe l0
              ; exit [%0]
              ...
            "#],
        );

        // i64
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i64 = load %0
              %2: i64 = 7
              %3: i1 = icmp ugt %1, %2
              guard true, %3, []
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              ; %1: i64 = load %0
              ; %2: i64 = 7
              ; %3: i1 = icmp ugt %1, %2
              ; guard true, %3, []
              cmp qword [r.64.x], 7
              jbe l0
              ; exit [%0]
              ...
            "#],
        );
    }

    #[test]
    fn cg_icmp() {
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: i1 = icmp eq %0, %1
              blackbox %2
              exit [%0, %1]
            ",
            &["
              ...
              ; %2: i1 = icmp eq %0, %1
              cmp r.32.x, r.32.y
              sete r.8._
              ...
            "],
        );
    }

    #[test]
    fn cg_inttoptr() {
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: ptr = inttoptr %0
              blackbox %1
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: i32 = arg [Reg("r.64.x")]
              ......
              mov r.32.x, r.32.x
              ; %1: ptr = inttoptr %0
              ...
            "#],
        );

        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: ptr = inttoptr %0
              blackbox %1
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: i64 = arg [Reg("r.64.x")]
              ......
              ; %1: ptr = inttoptr %0
              ...
            "#],
        );
    }

    #[test]
    fn cg_load_float() {
        // double
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: double = load %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %1: double = load %0
              movsd fp.128._, [r.64._]
              ...
            "],
        );

        // float
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: float = load %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %1: float = load %0
              movss fp.128._, [r.64._]
              ...
            "],
        );
    }

    #[test]
    fn cg_load_int() {
        // i8
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i8 = load %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %1: i8 = load %0
              movzx r.32._, byte [r.64._]
              ...
            "],
        );

        // i16
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i16 = load %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %1: i16 = load %0
              movzx r.32._, word [r.64._]
              ...
            "],
        );

        // i32
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i32 = load %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %1: i32 = load %0
              mov r.32._, [r.64._]
              ...
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i64 = load %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %1: i64 = load %0
              mov r.64._, [r.64._]
              ...
            "],
        );

        // ptradd optimisation
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: ptr = ptradd %0, 8
              %2: i8 = load %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %2: i8 = load %1
              movzx r.32._, byte [r.64._+8]
              ...
            "],
        );

        // Load and sext in one go optimisation

        // i8
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i8 = load %0
              %2: i64 = sext %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %1: i8 = load %0
              movsx r.64._, byte [r.64._]
              ; %2: i64 = sext %1
              ; blackbox %2
              ; exit [%0]
            "],
        );

        // i16
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i16 = load %0
              %2: i64 = sext %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %1: i16 = load %0
              movsx r.64._, word [r.64._]
              ; %2: i64 = sext %1
              ; blackbox %2
              ; exit [%0]
            "],
        );

        // i32
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i32 = load %0
              %2: i64 = sext %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %1: i32 = load %0
              movsxd r.64._, [r.64._]
              ; %2: i64 = sext %1
              ; blackbox %2
              ; exit [%0]
            "],
        );

        // There is no i64 case because LLVM IR does not allow `sext` to/from the same bit size.

        // Load and zext in one go optimisation

        // i8
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i8 = load %0
              %2: i64 = zext %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %1: i8 = load %0
              movzx r.32._, byte [r.64._]
              ; %2: i64 = zext %1
              ; blackbox %2
              ; exit [%0]
            "],
        );

        // i16
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i16 = load %0
              %2: i64 = zext %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %1: i16 = load %0
              movzx r.32._, word [r.64._]
              ; %2: i64 = zext %1
              ; blackbox %2
              ; exit [%0]
            "],
        );

        // i32
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i32 = load %0
              %2: i64 = zext %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %1: i32 = load %0
              mov r.32._, [r.64._]
              ; %2: i64 = zext %1
              ; blackbox %2
              ; exit [%0]
            "],
        );

        // There is no i64 case because LLVM IR does not allow `sext` to/from the same bit size.
    }

    #[test]
    fn cg_lshr() {
        // Constant RHS

        // i16
        codegen_and_test(
            "
              %0: i16 = arg [reg]
              %1: i16 = 3
              %2: i16 = lshr %0, %1
              blackbox %2
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: i16 = arg [Reg("r.64.x")]
              ...
              and r.32.x, 0xFFFF
              ...
              ; %2: i16 = lshr %0, %1
              shr r.32.x, 3
              ...
            "#],
        );

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 3
              %2: i32 = lshr %0, %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %2: i32 = lshr %0, %1
              shr r.32._, 3
              ...
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 3
              %2: i64 = lshr %0, %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %2: i64 = lshr %0, %1
              shr r.64._, 3
              ...
            "],
        );

        // Variable RHS

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: i32 = lshr %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i32 = lshr %0, %1
              shr r.32.x, cl
              ...
            "],
        );
    }

    #[test]
    fn cg_mul() {
        // i8
        codegen_and_test(
            r#"
              %0: i8 = arg [reg "R8"]
              %1: i8 = arg [reg "R9"]
              %2: i8 = mul %0, %1
              exit [%0, %2]
            "#,
            &["
              ...
              mov rax, r8
              ...
              ; %2: i8 = mul %0, %1
              mul r.32._
              ...
            "],
        );

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: i32 = mul %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i32 = mul %0, %1
              mul r.32._
              ...
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = arg [reg]
              %2: i64 = mul %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i64 = mul %0, %1
              mul r.64._
              ...
            "],
        );
    }

    #[test]
    fn cg_or() {
        // Constant RHS

        // i8
        codegen_and_test(
            "
              %0: i8 = arg [reg]
              %1: i8 = 3
              %2: i8 = or %0, %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %2: i8 = or %0, %1
              or r.32._, 3
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i8 = arg [reg]
              %1: i8 = -1
              %2: i8 = or %0, %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %2: i8 = or %0, %1
              or r.32._, 0xFF
              ...
            "],
        );

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 3
              %2: i32 = or %0, %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %2: i32 = or %0, %1
              or r.32._, 3
              ...
            "],
        );

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: i32 = or %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i32 = or %0, %1
              or r.32._, r.32._
              ...
            "],
        );
    }

    #[test]
    fn cg_ptradd() {
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i64 = arg [reg]
              %2: ptr = ptradd %0, 1
              exit [%2, %1]
            ",
            &["
              ...
              ; %2: ptr = ptradd %0, 1
              lea r.64._, [r.64.x+1]
              ...
            "],
        );
    }

    #[test]
    fn cg_ptrtoint() {
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i32 = ptrtoint %0
              %2: ptr = inttoptr %1
              exit [%2]
            ",
            &[r#"
              ...
              ; %0: ptr = arg ...
              ; %1: i32 = ptrtoint %0
              ; %2: ptr = inttoptr %1
              ; exit [%2]
            "#],
        );

        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i64 = ptrtoint %0
              %2: ptr = inttoptr %1
              exit [%2]
            ",
            &[r#"
              ...
              ; %0: ptr = arg ...
              ; %1: i64 = ptrtoint %0
              ; %2: ptr = inttoptr %1
              ; exit [%2]
            "#],
        );

        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i32 = ptrtoint %0
              %2: i64 = zext %1
              %3: ptr = inttoptr %2
              exit [%3]
            ",
            &[r#"
              ...
              ; %0: ptr = arg ...
              ; %1: i32 = ptrtoint %0
              ; %2: i64 = zext %1
              ; %3: ptr = inttoptr %2
              ; exit [%3]
            "#],
        );
    }

    #[test]
    fn cg_return() {
        codegen_and_test(
            "
              %0: i8 = arg [reg]
              return
            ",
            &["
              ...
              ; return
              mov rsp, rbp
              sub rsp, 0x28
              pop rbx
              pop r12
              pop r13
              pop r14
              pop r15
              pop rbp
              ret
            "],
        );
    }

    #[test]
    fn cg_sdiv() {
        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = arg [reg]
              %2: i64 = sdiv %0, %1
              exit [%2, %2]
            ",
            &["
              ...
              ; %2: i64 = sdiv %0, %1
              cqo
              idiv r.64.x
              ...
            "],
        );
    }

    #[test]
    fn cg_select() {
        // i1
        codegen_and_test(
            "
              %0: i1 = arg [reg]
              %1: i1 = arg [reg]
              %2: i1 = arg [reg]
              %3: i1 = select %0, %1, %2
              exit [%0, %3, %2]
            ",
            &["
              ...
              ; %3: i1 = select %0, %1, %2
              bt r.32.x, 0
              cmovae r.32.y, r.32.z
              ...
            "],
        );

        // i32
        codegen_and_test(
            "
              %0: i1 = arg [reg]
              %1: i32 = arg [reg]
              %2: i32 = arg [reg]
              %3: i32 = select %0, %1, %2
              exit [%0, %3, %2]
            ",
            &["
              ...
              ; %3: i32 = select %0, %1, %2
              bt r.32.x, 0
              cmovae r.32.y, r.32.z
              ...
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: i1 = arg [reg]
              %1: i64 = arg [reg]
              %2: i64 = arg [reg]
              %3: i64 = select %0, %1, %2
              exit [%0, %3, %2]
            ",
            &["
              ...
              ; %3: i64 = select %0, %1, %2
              bt r.32.x, 0
              cmovae r.64.y, r.64.z
              ...
            "],
        );

        // ptr
        codegen_and_test(
            "
              %0: i1 = arg [reg]
              %1: ptr = arg [reg]
              %2: ptr = arg [reg]
              %3: ptr = select %0, %1, %2
              exit [%0, %3, %2]
            ",
            &["
              ...
              ; %3: ptr = select %0, %1, %2
              bt r.32.x, 0
              cmovae r.64.y, r.64.z
              ...
            "],
        );
    }

    #[test]
    fn cg_sext() {
        codegen_and_test(
            "
              %0: i1 = arg [reg]
              %1: i1 = add %0, %0
              %2: i64 = sext %0
              blackbox %2
              exit [%1]
            ",
            &[r#"
              ...
              ; %2: i64 = sext %0
              ; blackbox %2
              ; exit [%1]
            "#],
        );
    }

    #[test]
    fn cg_sitofp() {
        // float
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: float = sitofp %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %1: float = sitofp %0
              cvtsi2ss fp.128.x, r.32.x
              ; blackbox %1
              ; exit [%0]
            "],
        );

        // double

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: double = sitofp %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %1: double = sitofp %0
              cvtsi2sd fp.128._, r.32._
              ; blackbox %1
              ; exit [%0]
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: double = sitofp %0
              blackbox %1
              exit [%0]
            ",
            &["
              ...
              ; %1: double = sitofp %0
              cvtsi2sd fp.128._, r.64._
              ; blackbox %1
              ; exit [%0]
            "],
        );
    }

    #[test]
    fn cg_shl() {
        // Constant RHS

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 3
              %2: i32 = shl %0, %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %2: i32 = shl %0, %1
              shl r.32._, 3
              ...
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 3
              %2: i64 = shl %0, %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %2: i64 = shl %0, %1
              shl r.64._, 3
              ...
            "],
        );

        // Variable RHS

        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: i32 = shl %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i32 = shl %0, %1
              shl r.32.x, cl
              ...
            "],
        );
    }

    #[test]
    fn cg_smax() {
        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = arg [reg]
              %2: i64 = smax %0, %1
              exit [%2, %2]
            ",
            &["
              ...
              ; %2: i64 = smax %0, %1
              cmp r.64.x, r.64.y
              cmovl r.64.x, r.64.y
              ...
            "],
        );
    }

    #[test]
    fn cg_srem() {
        // i64
        codegen_and_test(
            "
              extern f(i64)

              %0: i64 = arg [reg]
              %1: i64 = arg [reg]
              %2: ptr = arg [reg]
              %3: i64 = srem %0, %1
              call f %2(%3)
              exit [%0, %1, %2]
            ",
            &["
              ...
              ; %3: i64 = srem %0, %1
              cqo
              idiv r.64._
              ...
              mov rdi, rdx
              ...
              ; call %2(%3)
              ...
            "],
        );

        // i32
        codegen_and_test(
            "
              extern f(i32)

              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: ptr = arg [reg]
              %3: i32 = srem %0, %1
              call f %2(%3)
              exit [%0, %1, %2]
            ",
            &["
              ...
              ; %3: i32 = srem %0, %1
              cqo
              idiv r.64._
              ...
              mov rdi, rdx
              ...
              ; call %2(%3)
              ...
            "],
        );

        // i16
        codegen_and_test(
            "
              extern f(i16)

              %0: i16 = arg [reg]
              %1: i16 = arg [reg]
              %2: ptr = arg [reg]
              %3: i16 = srem %0, %1
              call f %2(%3)
              exit [%0, %1, %2]
            ",
            &["
              ...
              ; %3: i16 = srem %0, %1
              cqo
              idiv r.64._
              ...
              mov rdi, rdx
              ...
              ; call %2(%3)
              ...
            "],
        );

        // i8
        codegen_and_test(
            "
              extern f(i8)

              %0: i8 = arg [reg]
              %1: i8 = arg [reg]
              %2: ptr = arg [reg]
              %3: i8 = srem %0, %1
              call f %2(%3)
              exit [%0, %1, %2]
            ",
            &["
              ...
              ; %3: i8 = srem %0, %1
              cqo
              idiv r.64._
              ...
              mov rdi, rdx
              ...
              ; call %2(%3)
              ...
            "],
        );
    }

    #[test]
    fn cg_store_float() {
        // double
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: double = arg [reg]
              store %1, %0
              exit [%0, %1]
            ",
            &["
              ...
              ; store %1, %0
              movsd [r.64._], fp.128._
              ...
            "],
        );

        // float
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: float = arg [reg]
              store %1, %0
              exit [%0, %1]
            ",
            &["
              ...
              ; store %1, %0
              movss [r.64._], fp.128._
              ...
            "],
        );
    }

    #[test]
    fn cg_store_int() {
        // i8
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i8 = arg [reg]
              store %1, %0
              exit [%0, %1]
            ",
            &["
              ...
              ; store %1, %0
              mov [r.64.x], r.8.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i8 = 2
              store %1, %0
              exit [%0]
            ",
            &["
              ...
              ; store %1, %0
              mov byte [r.64.x], 2
              ...
            "],
        );

        // i16
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i16 = arg [reg]
              store %1, %0
              exit [%0, %1]
            ",
            &["
              ...
              ; store %1, %0
              mov [r.64.x], r.16.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i16 = 0x200
              store %1, %0
              exit [%0]
            ",
            &["
              ...
              ; store %1, %0
              mov word [r.64.x], 0x200
              ...
            "],
        );

        // i32
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i32 = arg [reg]
              store %1, %0
              exit [%0, %1]
            ",
            &["
              ...
              ; store %1, %0
              mov [r.64.x], r.32.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i32 = 0x2000
              store %1, %0
              exit [%0]
            ",
            &["
              ...
              ; store %1, %0
              mov dword [r.64.x], 0x2000
              ...
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i64 = arg [reg]
              store %1, %0
              exit [%0, %1]
            ",
            &["
              ...
              ; store %1, %0
              mov [r.64.x], r.64.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i64 = 0x20000
              store %1, %0
              exit [%0]
            ",
            &["
              ...
              ; store %1, %0
              mov qword [r.64.x], 0x20000
              ...
            "],
        );

        // ptradd optimisation
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i8 = arg [reg]
              %2: ptr = ptradd %0, 8
              store %1, %2
              exit [%0, %1]
            ",
            &["
              ...
              ; store %1, %2
              mov [r.64.x+8], r.8.y
              ...
            "],
        );

        // load-add-const-store optimisation

        // i8
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i8 = load %0
              %2: i8 = 42
              %3: i8 = add %1, %2
              store %3, %0
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              ; %1: i8 = load %0
              ; %2: i8 = 42
              ; %3: i8 = add %1, %2
              ; store %3, %0
              add byte [r.64.x], 0x2A
              ; exit [%0]
            "#],
        );

        codegen_and_test(
            "
              extern f()

              %0: ptr = arg [reg]
              %1: ptr = arg [reg]
              %2: i8 = load %0
              %3: i8 = 42
              %4: i8 = add %2, %3
              call f %1()
              store %4, %0
              exit [%0, %1]
            ",
            &[r#"
              ...
              ; %2: i8 = load %0
              movzx r.32.x, byte [r.64.y]
              ; %3: i8 = 42
              ; %4: i8 = add %2, %3
              add r.32.x, 0x2A
              ; call %1()
              call r.64._
              ; store %4, %0
              mov [r.64.y], r.8.x
              ; exit [%0, %1]
            "#],
        );

        // i16
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i16 = load %0
              %2: i16 = 42
              %3: i16 = add %1, %2
              store %3, %0
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              ; %1: i16 = load %0
              ; %2: i16 = 42
              ; %3: i16 = add %1, %2
              ; store %3, %0
              add word [r.64.x], 0x2A
              ; exit [%0]
            "#],
        );

        codegen_and_test(
            "
              extern f()

              %0: ptr = arg [reg]
              %1: ptr = arg [reg]
              %2: i16 = load %0
              %3: i16 = 42
              %4: i16 = add %2, %3
              call f %1()
              store %4, %0
              exit [%0, %1]
            ",
            &[r#"
              ...
              ; %2: i16 = load %0
              movzx r.32.x, word [r.64.y]
              ; %3: i16 = 42
              ; %4: i16 = add %2, %3
              add r.32.x, 0x2A
              ; call %1()
              call r.64._
              ; store %4, %0
              mov [r.64.y], r.16.x
              ; exit [%0, %1]
            "#],
        );

        // i32
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i32 = load %0
              %2: i32 = 42
              %3: i32 = add %1, %2
              store %3, %0
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              ; %1: i32 = load %0
              ; %2: i32 = 42
              ; %3: i32 = add %1, %2
              ; store %3, %0
              add dword [r.64.x], 0x2A
              ; exit [%0]
            "#],
        );

        codegen_and_test(
            "
              extern f()

              %0: ptr = arg [reg]
              %1: ptr = arg [reg]
              %2: i32 = load %0
              %3: i32 = 42
              %4: i32 = add %2, %3
              call f %1()
              store %4, %0
              exit [%0, %1]
            ",
            &[r#"
              ...
              ; %2: i32 = load %0
              mov r.32.x, [r.64.y]
              ; %3: i32 = 42
              ; %4: i32 = add %2, %3
              add r.32.x, 0x2A
              ; call %1()
              call r.64._
              ; store %4, %0
              mov [r.64.y], r.32.x
              ; exit [%0, %1]
            "#],
        );

        // i64
        codegen_and_test(
            "
              %0: ptr = arg [reg]
              %1: i64 = load %0
              %2: i64 = 42
              %3: i64 = add %1, %2
              store %3, %0
              exit [%0]
            ",
            &[r#"
              ...
              ; %0: ptr = arg [Reg("r.64.x")]
              ; %1: i64 = load %0
              ; %2: i64 = 42
              ; %3: i64 = add %1, %2
              ; store %3, %0
              add qword [r.64.x], 0x2A
              ; exit [%0]
            "#],
        );

        codegen_and_test(
            "
              extern f()

              %0: ptr = arg [reg]
              %1: ptr = arg [reg]
              %2: i64 = load %0
              %3: i64 = 42
              %4: i64 = add %2, %3
              call f %1()
              store %4, %0
              exit [%0, %1]
            ",
            &[r#"
              ...
              ; %2: i64 = load %0
              mov r.64.x, [r.64.y]
              ; %3: i64 = 42
              ; %4: i64 = add %2, %3
              add r.64.x, 0x2A
              ; call %1()
              call r.64._
              ; store %4, %0
              mov [r.64.y], r.64.x
              ; exit [%0, %1]
            "#],
        );
    }

    #[test]
    fn cg_sub() {
        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: i32 = sub %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i32 = sub %0, %1
              sub r.64.x, r.64.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 0
              %2: i32 = sub %1, %0
              exit [%2]
            ",
            &["
              ...
              ; %2: i32 = sub %1, %0
              neg r.64._
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 32
              %2: i32 = sub %0, %1
              exit [%2]
            ",
            &["
              ...
              ; %2: i32 = sub %0, %1
              sub r.64.x, 0x20
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = 0xFFFFFFFF
              %2: i32 = sub %0, %1
              exit [%2]
            ",
            &["
              ...
              ; %2: i32 = sub %0, %1
              sub r.64.x, 0xFFFFFFFFFFFFFFFF
              ...
            "],
        );

        // i64
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = arg [reg]
              %2: i64 = sub %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i64 = sub %0, %1
              sub r.64.x, r.64.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 0
              %2: i64 = sub %1, %0
              exit [%2]
            ",
            &["
              ...
              ; %2: i64 = sub %1, %0
              neg r.64._
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 32
              %2: i64 = sub %0, %1
              exit [%2]
            ",
            &["
              ...
              ; %2: i64 = sub %0, %1
              sub r.64.x, 0x20
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 0xFFFFFFFF
              %2: i64 = sub %0, %1
              exit [%2]
            ",
            &["
              ...
              mov r.32.y, 0xFFFFFFFF
              ; %2: i64 = sub %0, %1
              sub r.64.x, r.64.y
              ...
            "],
        );

        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = 0xFFFFFFFFFFFFFFFF
              %2: i64 = sub %1, %0
              exit [%2]
            ",
            &["
              ...
              mov r.64.x, 0xFFFFFFFFFFFFFFFF
              ; %2: i64 = sub %1, %0
              sub r.64.x, r.64._
              ...
            "],
        );
    }

    #[test]
    fn cg_trunc() {
        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: i64 = add %0, %0
              %2: i1 = trunc %1
              blackbox %2
              exit [%0]
            ",
            &["
              ...
              ; %2: i1 = trunc %1
              ; blackbox %2
              ; exit [%0]
            "],
        );
    }

    #[test]
    fn cg_udiv() {
        // i64
        codegen_and_test(
            "
              extern f(i64)

              %0: i64 = arg [reg]
              %1: i64 = arg [reg]
              %2: ptr = arg [reg]
              %3: i64 = udiv %0, %1
              call f %2(%3)
              exit [%0, %1, %2]
            ",
            &["
              ...
              ; %3: i64 = udiv %0, %1
              xor edx, edx
              div r.64._
              ...
              mov rdi, rax
              ...
              ; call %2(%3)
              ...
            "],
        );

        // i32
        codegen_and_test(
            "
              extern f(i32)

              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: ptr = arg [reg]
              %3: i32 = udiv %0, %1
              call f %2(%3)
              exit [%0, %1, %2]
            ",
            &["
              ...
              ; %3: i32 = udiv %0, %1
              xor edx, edx
              div r.64._
              ...
              mov rdi, rax
              ...
              ; call %2(%3)
              ...
            "],
        );

        // i16
        codegen_and_test(
            "
              extern f(i16)

              %0: i16 = arg [reg]
              %1: i16 = arg [reg]
              %2: ptr = arg [reg]
              %3: i16 = udiv %0, %1
              call f %2(%3)
              exit [%0, %1, %2]
            ",
            &["
              ...
              ; %3: i16 = udiv %0, %1
              xor edx, edx
              div r.64._
              ...
              mov rdi, rax
              ...
              ; call %2(%3)
              ...
            "],
        );

        // i8
        codegen_and_test(
            "
              extern f(i8)

              %0: i8 = arg [reg]
              %1: i8 = arg [reg]
              %2: ptr = arg [reg]
              %3: i8 = udiv %0, %1
              call f %2(%3)
              exit [%0, %1, %2]
            ",
            &["
              ...
              ; %3: i8 = udiv %0, %1
              xor edx, edx
              div r.64._
              ...
              mov rdi, rax
              ...
              ; call %2(%3)
              ...
            "],
        );
    }

    #[test]
    fn cg_uitofp() {
        // double

        codegen_and_test(
            "
              %0: i64 = arg [reg]
              %1: double = uitofp %0
              blackbox %1
              exit [%0]
            ",
            &[
                r#"
              ...
              ; %0: i64 = arg [Reg("r.64.x")]
              ; %1: double = uitofp %0
              movq fp.128.x, r.64.x
              punpckldq fp.128.x, l0
              subpd fp.128.x, l1
              movapd fp.128.y, fp.128.x
              unpckhpd fp.128.y, fp.128.x
              addsd fp.128.y, fp.128.x
              ; blackbox %1
              ; exit [%0]
              ; l0
              db 0, 0, 0x30, 0x43, 0, 0, 0x30, 0x45, 0, 0, 0, 0, 0, 0, 0, 0
              ; l1
              db 0, 0, 0, 0, 0, 0, 0x30, 0x43, 0, 0, 0, 0, 0, 0, 0x30, 0x45
            "#,
                r#"
              ...
              ; %0: i64 = arg [Reg("r.64.x")]
              ; %1: double = uitofp %0
              movq fp.128.x, r.64.x
              punpckldq fp.128.x, l0
              subpd fp.128.x, l1
              movapd fp.128.y, fp.128.x
              unpckhpd fp.128.y, fp.128.x
              addsd fp.128.y, fp.128.x
              ; blackbox %1
              ; exit [%0]
              ; l1
              db 0, 0, 0, 0, 0, 0, 0x30, 0x43, 0, 0, 0, 0, 0, 0, 0x30, 0x45
              ; l0
              db 0, 0, 0x30, 0x43, 0, 0, 0x30, 0x45, 0, 0, 0, 0, 0, 0, 0, 0
            "#,
            ],
        );
    }

    #[test]
    fn cg_xor() {
        // i32
        codegen_and_test(
            "
              %0: i32 = arg [reg]
              %1: i32 = arg [reg]
              %2: i32 = xor %0, %1
              exit [%0, %2]
            ",
            &["
              ...
              ; %2: i32 = xor %0, %1
              xor r.32._, r.32._
              ...
            "],
        );
    }

    #[test]
    fn cg_zext() {
        codegen_and_test(
            "
              %0: i1 = arg [reg]
              %1: i1 = add %0, %0
              %2: i64 = zext %0
              blackbox %2
              exit [%1]
            ",
            &[r#"
              ...
              ; %2: i64 = zext %0
              ; blackbox %2
              ; exit [%1]
            "#],
        );
    }
}
